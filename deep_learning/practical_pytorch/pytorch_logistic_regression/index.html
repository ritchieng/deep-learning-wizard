
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="We try to make learning deep learning, deep bayesian learning, and deep reinforcement learning math and code easier. Open-source and used by thousands globally.">
      
      
        <meta name="author" content="Ritchie Ng">
      
      
        <link rel="canonical" href="https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_logistic_regression/">
      
      
        <link rel="prev" href="../pytorch_linear_regression/">
      
      
        <link rel="next" href="../pytorch_feedforward_neuralnetwork/">
      
      
      <link rel="icon" href="../../../docs/assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.31">
    
    
      
        <title>Logistic Regression - Deep Learning Wizard</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.3cba04c6.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","UA-122083328-1"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","UA-122083328-1",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=UA-122083328-1",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  <link rel="stylesheet" href="../../../assets/stylesheets/custom.00c04c01.min.css">

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#logistic-regression-with-pytorch" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
            
  For updates follow us on
  <a href="https://twitter.com/deeplearningwiz">
    <span class="twemoji twitter">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </span>
    <strong>Twitter</strong>
  </a>
  <a href="https://www.linkedin.com/company/deeplearningwizard">
    <span class="twemoji linkedin" style="color:#0077B5">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </span>
    <strong>Linkedin</strong>
  </a>
  <a href="https://www.facebook.com/DeepLearningWizard/">
    <span class="twemoji facebook" style="color:#4267B2">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256c0 120 82.7 220.8 194.2 248.5V334.2h-52.8V256h52.8v-33.7c0-87.1 39.4-127.5 125-127.5 16.2 0 44.2 3.2 55.7 6.4V172c-6-.6-16.5-1-29.6-1-42 0-58.2 15.9-58.2 57.2V256h83.6l-14.4 78.2H287v175.9C413.8 494.8 512 386.9 512 256z"/></svg>
    </span>
    <strong>Facebook</strong>
  </a>
  or subscribe to our channel on
  <a href="https://www.youtube.com/channel/UCJz2MIjiCosOQCwhnsYxeEw">
    <span class="twemoji twitter" style="color:#FF0000">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg>
    </span>
    <strong>YouTube</strong>
  </a>

          </div>
          
        </aside>
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Deep Learning Wizard" class="md-header__button md-logo" aria-label="Deep Learning Wizard" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M24 32c13.3 0 24 10.7 24 24v352c0 13.3 10.7 24 24 24h416c13.3 0 24 10.7 24 24s-10.7 24-24 24H72c-39.8 0-72-32.2-72-72V56c0-13.3 10.7-24 24-24zm104 104c0-13.3 10.7-24 24-24h208c13.3 0 24 10.7 24 24s-10.7 24-24 24H152c-13.3 0-24-10.7-24-24zm24 72h144c13.3 0 24 10.7 24 24s-10.7 24-24 24H152c-13.3 0-24-10.7-24-24s10.7-24 24-24zm0 96h272c13.3 0 24 10.7 24 24s-10.7 24-24 24H152c-13.3 0-24-10.7-24-24s10.7-24 24-24z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Deep Learning Wizard
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Logistic Regression
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ritchieng/deep-learning-wizard" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ritchieng/deep-learning-wizard
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../about/" class="md-tabs__link">
          
  
  About

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../intro/" class="md-tabs__link">
          
  
  Deep Learning

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../language_model/intro/" class="md-tabs__link">
          
  
  Language Model

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../machine_learning/intro/" class="md-tabs__link">
          
  
  Machine Learning

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../programming/intro/" class="md-tabs__link">
          
  
  Programming

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../data_engineering/nosql/cassandra/intro/" class="md-tabs__link">
          
  
  Data Engineering

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../blog/" class="md-tabs__link">
          
  
  Blog

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Deep Learning Wizard" class="md-nav__button md-logo" aria-label="Deep Learning Wizard" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M24 32c13.3 0 24 10.7 24 24v352c0 13.3 10.7 24 24 24h416c13.3 0 24 10.7 24 24s-10.7 24-24 24H72c-39.8 0-72-32.2-72-72V56c0-13.3 10.7-24 24-24zm104 104c0-13.3 10.7-24 24-24h208c13.3 0 24 10.7 24 24s-10.7 24-24 24H152c-13.3 0-24-10.7-24-24zm24 72h144c13.3 0 24 10.7 24 24s-10.7 24-24 24H152c-13.3 0-24-10.7-24-24s10.7-24 24-24zm0 96h272c13.3 0 24 10.7 24 24s-10.7 24-24 24H152c-13.3 0-24-10.7-24-24s10.7-24 24-24z"/></svg>

    </a>
    Deep Learning Wizard
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ritchieng/deep-learning-wizard" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ritchieng/deep-learning-wizard
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    About
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            About
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About Us
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../review/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reviews
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Deep Learning
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Deep Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../course_progression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Course Progression
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Practical Deep Learning with PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Practical Deep Learning with PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_matrices/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Matrices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_gradients/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gradients
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_linear_regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linear Regression
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Logistic Regression
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Logistic Regression
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#about-logistic-regression" class="md-nav__link">
    <span class="md-ellipsis">
      About Logistic Regression
    </span>
  </a>
  
    <nav class="md-nav" aria-label="About Logistic Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#logistic-regression-basics" class="md-nav__link">
    <span class="md-ellipsis">
      Logistic Regression Basics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Logistic Regression Basics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#classification-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Classification algorithm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#basic-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      Basic Comparison
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inputoutput-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      Input/Output Comparison
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problems-of-linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Problems of Linear Regression
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic-regression-in-depth" class="md-nav__link">
    <span class="md-ellipsis">
      Logistic Regression In-Depth
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Logistic Regression In-Depth">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#predicting-probability" class="md-nav__link">
    <span class="md-ellipsis">
      Predicting Probability
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic-function-g" class="md-nav__link">
    <span class="md-ellipsis">
      Logistic Function g()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax-function-g" class="md-nav__link">
    <span class="md-ellipsis">
      Softmax Function g()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-entropy-function-d-for-2-class" class="md-nav__link">
    <span class="md-ellipsis">
      Cross Entropy Function D() for 2 Class
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-entropy-function-d-for-more-than-2-class" class="md-nav__link">
    <span class="md-ellipsis">
      Cross Entropy Function D() for More Than 2 Class
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-entropy-loss-over-n-samples" class="md-nav__link">
    <span class="md-ellipsis">
      Cross Entropy Loss over N samples
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-a-logistic-regression-model-with-pytorch" class="md-nav__link">
    <span class="md-ellipsis">
      Building a Logistic Regression Model with PyTorch
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Building a Logistic Regression Model with PyTorch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#steps" class="md-nav__link">
    <span class="md-ellipsis">
      Steps
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1a-loading-mnist-train-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1a: Loading MNIST Train Dataset
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Step 1a: Loading MNIST Train Dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#displaying-mnist" class="md-nav__link">
    <span class="md-ellipsis">
      Displaying MNIST
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1b-loading-mnist-test-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1b: Loading MNIST Test Dataset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-make-dataset-iterable" class="md-nav__link">
    <span class="md-ellipsis">
      Step 2: Make Dataset Iterable
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-building-model" class="md-nav__link">
    <span class="md-ellipsis">
      Step 3: Building Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-instantiate-model-class" class="md-nav__link">
    <span class="md-ellipsis">
      Step 4: Instantiate Model Class
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-5-instantiate-loss-class" class="md-nav__link">
    <span class="md-ellipsis">
      Step 5: Instantiate Loss Class
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-6-instantiate-optimizer-class" class="md-nav__link">
    <span class="md-ellipsis">
      Step 6: Instantiate Optimizer Class
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-7-train-model" class="md-nav__link">
    <span class="md-ellipsis">
      Step 7: Train Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Step 7: Train Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#break-down-accuracy-calculation" class="md-nav__link">
    <span class="md-ellipsis">
      Break Down Accuracy Calculation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#saving-model" class="md-nav__link">
    <span class="md-ellipsis">
      Saving Model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-a-logistic-regression-model-with-pytorch-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      Building a Logistic Regression Model with PyTorch (GPU)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    <span class="md-ellipsis">
      Citation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_feedforward_neuralnetwork/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Feedforward Neural Networks (FNN)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_convolutional_neuralnetwork/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Convolutional Neural Networks (CNN)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_recurrent_neuralnetwork/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recurrent Neural Networks (RNN)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_lstm_neuralnetwork/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Long Short Term Memory Neural Networks (LSTM)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_autoencoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autoencoders (AE)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_fc_overcomplete_ae/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fully-connected Overcomplete Autoencoder (AE)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Improving Deep Learning with PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            Improving Deep Learning with PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/derivative_gradient_jacobian/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Derivative, Gradient and Jacobian
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/forwardpropagation_backpropagation_gradientdescent/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forward- and Backward-propagation and Gradient Descent (From Scratch FNN Regression)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/lr_scheduling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learning Rate Scheduling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/optimizers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimization Algorithms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/weight_initialization_activation_functions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Weight Initialization and Activation Functions
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" >
        
          
          <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Deep Reinforcement Learning with PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            Deep Reinforcement Learning with PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep_reinforcement_learning_pytorch/supervised_to_rl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Supervised Learning to Reinforcement Learning (RL)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep_reinforcement_learning_pytorch/bellman_mdp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Markov Decision Processes (MDP) and Bellman Equations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep_reinforcement_learning_pytorch/dynamic_programming_frozenlake/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Programming
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" >
        
          
          <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    From Scratch Deep Learning with Python/PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6">
            <span class="md-nav__icon md-icon"></span>
            From Scratch Deep Learning with Python/PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../fromscratch/fromscratch_logistic_regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    From Scratch Logistic Regression Classification
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_7" >
        
          
          <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Compute Optimization
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_7">
            <span class="md-nav__icon md-icon"></span>
            Compute Optimization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../production_pytorch/speed_optimization_basics_numba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Speed Optimization Basics Numba
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Language Model
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Language Model
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../language_model/intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Containers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            Containers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../language_model/containers/hpc_containers_apptainer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HPC Containers with Apptainer
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    LLMs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            LLMs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../language_model/llm/llm_intro_hyperparameter_tuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLMs Introduction and Hyperparameter Tuning
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" >
        
          
          <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    MMLMs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4">
            <span class="md-nav__icon md-icon"></span>
            MMLMs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../language_model/mmlm/mmlm_intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MMLMs Introduction
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_5" >
        
          
          <label class="md-nav__link" for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    RAG
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5">
            <span class="md-nav__icon md-icon"></span>
            RAG
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../language_model/rag/embedding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Embeddings Introduction
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Machine Learning
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Machine Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../machine_learning/intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    RAPIDS cuDF
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            RAPIDS cuDF
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../machine_learning/gpu/rapids_cudf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GPU DataFrames
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../machine_learning/gpu/gpu_fractional_differencing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GPU/CPU Fractional Differencing
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Programming
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Programming
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/cpp/cpp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/bash/bash/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bash
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/python/python/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/r/r/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    R
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/javascript/javascript/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Javascript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/electron/electron/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Electron
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/sympy/calculus_sympy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sympy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/numpycupy/linalg_numpy_cupy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NumPy and CuPy
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Data Engineering
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Data Engineering
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_1" >
        
          
          <label class="md-nav__link" for="__nav_7_1" id="__nav_7_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Cassandra (NoSQL)
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_1">
            <span class="md-nav__icon md-icon"></span>
            Cassandra (NoSQL)
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data_engineering/nosql/cassandra/intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data_engineering/nosql/cassandra/setting_up_cluster/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cassandra Cluster Setup
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Blog
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Blog
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_2" >
        
          
          <label class="md-nav__link" for="__nav_8_2" id="__nav_8_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Archive
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2019/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2019
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2018/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2018
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2017/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2017
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2016/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2016
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_3" >
        
          
          <label class="md-nav__link" for="__nav_8_3" id="__nav_8_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Categories
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/awards/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Awards
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/miscellaneous/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Miscellaneous
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/workshops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Workshops
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#about-logistic-regression" class="md-nav__link">
    <span class="md-ellipsis">
      About Logistic Regression
    </span>
  </a>
  
    <nav class="md-nav" aria-label="About Logistic Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#logistic-regression-basics" class="md-nav__link">
    <span class="md-ellipsis">
      Logistic Regression Basics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Logistic Regression Basics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#classification-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Classification algorithm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#basic-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      Basic Comparison
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inputoutput-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      Input/Output Comparison
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problems-of-linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Problems of Linear Regression
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic-regression-in-depth" class="md-nav__link">
    <span class="md-ellipsis">
      Logistic Regression In-Depth
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Logistic Regression In-Depth">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#predicting-probability" class="md-nav__link">
    <span class="md-ellipsis">
      Predicting Probability
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic-function-g" class="md-nav__link">
    <span class="md-ellipsis">
      Logistic Function g()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax-function-g" class="md-nav__link">
    <span class="md-ellipsis">
      Softmax Function g()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-entropy-function-d-for-2-class" class="md-nav__link">
    <span class="md-ellipsis">
      Cross Entropy Function D() for 2 Class
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-entropy-function-d-for-more-than-2-class" class="md-nav__link">
    <span class="md-ellipsis">
      Cross Entropy Function D() for More Than 2 Class
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-entropy-loss-over-n-samples" class="md-nav__link">
    <span class="md-ellipsis">
      Cross Entropy Loss over N samples
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-a-logistic-regression-model-with-pytorch" class="md-nav__link">
    <span class="md-ellipsis">
      Building a Logistic Regression Model with PyTorch
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Building a Logistic Regression Model with PyTorch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#steps" class="md-nav__link">
    <span class="md-ellipsis">
      Steps
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1a-loading-mnist-train-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1a: Loading MNIST Train Dataset
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Step 1a: Loading MNIST Train Dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#displaying-mnist" class="md-nav__link">
    <span class="md-ellipsis">
      Displaying MNIST
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1b-loading-mnist-test-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1b: Loading MNIST Test Dataset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-make-dataset-iterable" class="md-nav__link">
    <span class="md-ellipsis">
      Step 2: Make Dataset Iterable
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-building-model" class="md-nav__link">
    <span class="md-ellipsis">
      Step 3: Building Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-instantiate-model-class" class="md-nav__link">
    <span class="md-ellipsis">
      Step 4: Instantiate Model Class
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-5-instantiate-loss-class" class="md-nav__link">
    <span class="md-ellipsis">
      Step 5: Instantiate Loss Class
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-6-instantiate-optimizer-class" class="md-nav__link">
    <span class="md-ellipsis">
      Step 6: Instantiate Optimizer Class
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-7-train-model" class="md-nav__link">
    <span class="md-ellipsis">
      Step 7: Train Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Step 7: Train Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#break-down-accuracy-calculation" class="md-nav__link">
    <span class="md-ellipsis">
      Break Down Accuracy Calculation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#saving-model" class="md-nav__link">
    <span class="md-ellipsis">
      Saving Model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-a-logistic-regression-model-with-pytorch-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      Building a Logistic Regression Model with PyTorch (GPU)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    <span class="md-ellipsis">
      Citation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/ritchieng/deep-learning-wizard/edit/master/docs/deep_learning/practical_pytorch/pytorch_logistic_regression.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/ritchieng/deep-learning-wizard/raw/master/docs/deep_learning/practical_pytorch/pytorch_logistic_regression.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg>
    </a>
  


<h1 id="logistic-regression-with-pytorch">Logistic Regression with PyTorch<a class="headerlink" href="#logistic-regression-with-pytorch" title="Permanent link">&para;</a></h1>
<div class="admonition tip">
<p class="admonition-title">Run Jupyter Notebook</p>
<p>You can run the code for this section in this <a href="https://github.com/ritchieng/deep-learning-wizard/blob/master/docs/deep_learning/practical_pytorch/pytorch_logistic_regression.ipynb">jupyter notebook link</a>.</p>
</div>
<h2 id="about-logistic-regression">About Logistic Regression<a class="headerlink" href="#about-logistic-regression" title="Permanent link">&para;</a></h2>
<h3 id="logistic-regression-basics">Logistic Regression Basics<a class="headerlink" href="#logistic-regression-basics" title="Permanent link">&para;</a></h3>
<h4 id="classification-algorithm">Classification algorithm<a class="headerlink" href="#classification-algorithm" title="Permanent link">&para;</a></h4>
<ul>
<li>Example: Spam vs No Spam<ul>
<li>Input: Bunch of words</li>
<li>Output: Probability spam or not</li>
</ul>
</li>
</ul>
<h4 id="basic-comparison">Basic Comparison<a class="headerlink" href="#basic-comparison" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Linear regression</strong><ul>
<li>Output: numeric value given inputs</li>
</ul>
</li>
<li><strong>Logistic regression</strong>:<ul>
<li>Output: probability [0, 1] given input belonging to a class</li>
</ul>
</li>
</ul>
<h4 id="inputoutput-comparison">Input/Output Comparison<a class="headerlink" href="#inputoutput-comparison" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Linear regression: Multiplication</strong><ul>
<li>Input: [1]<ul>
<li>Output: 2</li>
</ul>
</li>
<li>Input: [2]<ul>
<li>Output: 4</li>
</ul>
</li>
<li>Trying to model the relationship <code>y = 2x</code></li>
</ul>
</li>
<li><strong>Logistic regression: Spam</strong><ul>
<li>Input: "Sign up to get 1 million dollars by tonight"<ul>
<li>Output: p = 0.8</li>
</ul>
</li>
<li>Input: "This is a receipt for your recent purchase with Amazon"<ul>
<li>Output: p = 0.3</li>
</ul>
</li>
<li><strong>p: probability it is spam</strong></li>
</ul>
</li>
</ul>
<h3 id="problems-of-linear-regression">Problems of Linear Regression<a class="headerlink" href="#problems-of-linear-regression" title="Permanent link">&para;</a></h3>
<ul>
<li>Example<ul>
<li>Fever</li>
<li><strong>Input</strong>: temperature</li>
<li><strong>Output</strong>: fever or no fever</li>
</ul>
</li>
<li>Remember<ul>
<li><strong>Linear regression</strong>: minimize error between points and line</li>
</ul>
</li>
</ul>
<div class="admonition bug">
<p class="admonition-title">Linear Regression Problem 1: Fever value can go negative (below 0) and positive (above 1)</p>
<p>If you simply tried to do a simple linear regression on this fever problem, you would realize an apparent error. Fever can go beyond 1 and below 0 which does not make sense in this context.
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">100</span><span class="p">,]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">colors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Fever&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Temperature&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></p>
</div>
<p><img alt="png" src="../pytorch_logistic_regression_files/pytorch_logistic_regression_5_1.png" /></p>
<div class="admonition bug">
<p class="admonition-title">Linear Regression Problem 2: Fever points are not predicted with the presence of outliers</p>
<p>Previously at least some points could be properly predicted. However, with the presence of outliers, everything goes wonky for simple linear regression, having no predictive capacity at all.
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">300</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">colors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Fever&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Temperature&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></p>
</div>
<p><img alt="png" src="../pytorch_logistic_regression_files/pytorch_logistic_regression_5_0.png" /></p>
<h3 id="logistic-regression-in-depth">Logistic Regression In-Depth<a class="headerlink" href="#logistic-regression-in-depth" title="Permanent link">&para;</a></h3>
<h4 id="predicting-probability">Predicting Probability<a class="headerlink" href="#predicting-probability" title="Permanent link">&para;</a></h4>
<ul>
<li>Linear regression doesn't work</li>
<li>Instead of predicting direct values: <strong>predict probability</strong></li>
</ul>
<p><img alt="" src="../images/cross_entropy_final_4.png" /></p>
<h4 id="logistic-function-g">Logistic Function g()<a class="headerlink" href="#logistic-function-g" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>"Two-class logistic regression"</strong></li>
<li><span class="arithmatex">\(\boldsymbol{y} = A\boldsymbol{x} + \boldsymbol{b}\)</span><ul>
<li>Where <span class="arithmatex">\(\boldsymbol{y}\)</span> is a vector comprising the 2-class prediction <span class="arithmatex">\(y_0\)</span> and <span class="arithmatex">\(y_1\)</span></li>
<li>Where the labels are <span class="arithmatex">\(y_0 = 0\)</span>  and <span class="arithmatex">\(y_1 = 1\)</span></li>
<li>Also, it's bolded because it's a vector, not a matrix.</li>
</ul>
</li>
<li><span class="arithmatex">\(g(y_1) = \frac {1} {1 + e^{-y_1}}\)</span><ul>
<li><span class="arithmatex">\(g(y_1)\)</span> = Estimated probability that <span class="arithmatex">\(y = 1\)</span></li>
</ul>
</li>
<li><span class="arithmatex">\(g(y_0) = 1 - g(y_1)\)</span><ul>
<li><span class="arithmatex">\(g(y_0)\)</span> = Estimated probability that <span class="arithmatex">\(y = 0\)</span></li>
</ul>
</li>
<li>For our illustration above, we have 4 classes, so we have to use softmax function explained below</li>
</ul>
<h4 id="softmax-function-g">Softmax Function g()<a class="headerlink" href="#softmax-function-g" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>"Multi-class logistic regression"</strong><ul>
<li>Generalization of logistic function, where you can derive back to the logistic function if you've a 2 class classification problem</li>
<li>Here, we will use a 4 class example (K = 4) as shown above to be very clear in how it relates back to that simple examaple.</li>
</ul>
</li>
<li><span class="arithmatex">\(\boldsymbol{y} = A\boldsymbol{x} + \boldsymbol{b}\)</span><ul>
<li>Where <span class="arithmatex">\(\boldsymbol{y}\)</span> is a vector comprising the 4-class prediction <span class="arithmatex">\(y_0, y_1, y_2, y_3\)</span></li>
<li>Where the 4 labels (K = 4) are <span class="arithmatex">\(y_0 = 0, y_1 = 1, y_2 = 2, y_3 = 3\)</span></li>
</ul>
</li>
<li><span class="arithmatex">\(g(y_i) = \frac {e^{y_i} } {\sum^K_i e^{y_i}}\)</span> where K = 4 because we have 4 classes<ul>
<li>To put numbers to this equation in relation to the illustration above where we've <span class="arithmatex">\(y_0 = 1.3, y_1 = 1.2, y = 4.5, y = 4.8\)</span><ul>
<li><span class="arithmatex">\(g(y_0) = \frac {e^{1.3}}{e^{1.3} + e^{1.2} + e^{4.5} + e^{4.8}} = 0.017\)</span></li>
<li><span class="arithmatex">\(g(y_1) = \frac {e^{1.2}}{e^{1.3} + e^{1.2} + e^{4.5} + e^{4.8}} = 0.015\)</span></li>
<li><span class="arithmatex">\(g(y_2) = \frac {e^{4.5}}{e^{1.3} + e^{1.2} + e^{4.5} + e^{4.8}} = 0.412\)</span></li>
<li><span class="arithmatex">\(g(y_3) = \frac {e^{4.8}}{e^{1.3} + e^{1.2} + e^{4.5} + e^{4.8}} = 0.556\)</span></li>
<li><span class="arithmatex">\(g(y_0) + g(y_1) + g(y_2) + g(y_3) = 1.0\)</span></li>
<li>All softmax outputs have to sum to one as they represent a probability distribution over K classes. </li>
</ul>
</li>
</ul>
</li>
<li>Take note how these numbers are not exactly as in the illustration in the softmax box but the concept is important (intentionally made so).<ul>
<li><span class="arithmatex">\(y_0\)</span> and <span class="arithmatex">\(y_1\)</span> are approximately similar in values and they return similar probabilities.</li>
<li>Similarly, <span class="arithmatex">\(y_2\)</span> and <span class="arithmatex">\(y_3\)</span> are approximately similar in values and they return similar probabilities.</li>
</ul>
</li>
</ul>
<div class="admonition bug">
<p class="admonition-title">Softmax versus Soft(arg)max</p>
<p>Do you know many researchers and anyone in deep learning in general use the term softmax when it should be soft(arg)max.</p>
<p>This is because soft(arg)max returns the probability distribution over K classes, a vector. </p>
<p>However, softmax only returns the max! This means you will be getting a scalar value versus a probability distribution.</p>
<p>According to my friend, Alfredo Canziani (postdoc in NYU under Yann Lecun), it was actually a mistake made in the original paper previously but it was too late because the term softmax was adopted. Full credits to him for this tip.</p>
</div>
<h4 id="cross-entropy-function-d-for-2-class">Cross Entropy Function D() for 2 Class<a class="headerlink" href="#cross-entropy-function-d-for-2-class" title="Permanent link">&para;</a></h4>
<ul>
<li>Take note that here, <span class="arithmatex">\(S\)</span> is our softmax outputs and <span class="arithmatex">\(L\)</span> are our labels</li>
<li><span class="arithmatex">\(D(S, L) = -(L log S + (1-L)log(1-S))\)</span><ul>
<li>If L = 0 (label)<ul>
<li><span class="arithmatex">\(D(S, 0) = - log(1-S)\)</span><ul>
<li><span class="arithmatex">\(- log(1-S)\)</span>: less positive if <span class="arithmatex">\(S \longrightarrow 0\)</span></li>
<li><span class="arithmatex">\(- log(1-S)\)</span>: more positive if <span class="arithmatex">\(S \longrightarrow 1\)</span> (BIGGER LOSS)</li>
</ul>
</li>
</ul>
</li>
<li>If L = 1 (label)<ul>
<li><span class="arithmatex">\(D(S, 1) = - log S\)</span><ul>
<li><span class="arithmatex">\(-log(S)\)</span>: less positive if <span class="arithmatex">\(S \longrightarrow 1\)</span></li>
<li><span class="arithmatex">\(-log(S)\)</span>: more positive if <span class="arithmatex">\(S \longrightarrow 0\)</span> (BIGGER LOSS)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Numerical example of bigger or small loss</p>
<p>You get a small error of 1e-5 if your label = 0 and your S is closer to 0 (very correct prediction).
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">math</span>
<span class="nb">print</span><span class="p">(</span><span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mf">0.00001</span><span class="p">))</span>
</code></pre></div></p>
<p>You get a large error of 11.51 if your label is 0 and S is near to 1 (very wrong prediction).
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mf">0.99999</span><span class="p">))</span> 
</code></pre></div></p>
<p>You get a small error of -1e-5 if your label is 1 and S is near 1 (very correct prediction).
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.99999</span><span class="p">))</span>
</code></pre></div></p>
<p>You get a big error of -11.51 if your label is 1 and S is near 0 (very wrong prediction).
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.00001</span><span class="p">))</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="mf">1.0000050000287824e-05</span>
<span class="mf">11.51292546497478</span>
<span class="mf">1.0000050000287824e-05</span>
<span class="mf">11.512925464970229</span>
</code></pre></div>
<h4 id="cross-entropy-function-d-for-more-than-2-class">Cross Entropy Function D() for More Than 2 Class<a class="headerlink" href="#cross-entropy-function-d-for-more-than-2-class" title="Permanent link">&para;</a></h4>
<ul>
<li>For the case where we have more than 2 class, we need a more generalized function</li>
<li><span class="arithmatex">\(D(S, L) = - \sum^K_1 L_i log(S_i)\)</span><ul>
<li><span class="arithmatex">\(K\)</span>: number of classes</li>
<li><span class="arithmatex">\(L_i\)</span>: label of i-th class, 1 if that's the class else 0</li>
<li><span class="arithmatex">\(S_i\)</span>: output of softmax for i-th class</li>
</ul>
</li>
</ul>
<h4 id="cross-entropy-loss-over-n-samples">Cross Entropy Loss over N samples<a class="headerlink" href="#cross-entropy-loss-over-n-samples" title="Permanent link">&para;</a></h4>
<ul>
<li>Goal: Minimizing Cross Entropy Loss, L</li>
<li><span class="arithmatex">\(Loss = \frac {1}{N} \sum_j^N D_j\)</span><ul>
<li><span class="arithmatex">\(D_j\)</span>: j-th sample of cross entropy function <span class="arithmatex">\(D(S, L)\)</span></li>
<li><span class="arithmatex">\(N\)</span>: number of samples</li>
<li><span class="arithmatex">\(Loss\)</span>: average cross entropy loss over N samples</li>
</ul>
</li>
</ul>
<h2 id="building-a-logistic-regression-model-with-pytorch">Building a Logistic Regression Model with PyTorch<a class="headerlink" href="#building-a-logistic-regression-model-with-pytorch" title="Permanent link">&para;</a></h2>
<p><img alt="" src="../images/lr2.png" /></p>
<h3 id="steps">Steps<a class="headerlink" href="#steps" title="Permanent link">&para;</a></h3>
<ul>
<li>Step 1: Load Dataset</li>
<li>Step 2: Make Dataset Iterable</li>
<li>Step 3: Create Model Class</li>
<li>Step 4: Instantiate Model Class</li>
<li>Step 5: Instantiate Loss Class</li>
<li>Step 6: Instantiate Optimizer Class</li>
<li>Step 7: Train Model</li>
</ul>
<h3 id="step-1a-loading-mnist-train-dataset">Step 1a: Loading MNIST Train Dataset<a class="headerlink" href="#step-1a-loading-mnist-train-dataset" title="Permanent link">&para;</a></h3>
<p><strong>Images from 1 to 9</strong></p>
<div class="admonition note">
<p class="admonition-title">Inspect length of training dataset</p>
<p>You can easily load MNIST dataset with PyTorch. Here we inspect the training set, where our algorithms will learn from, and you will discover it is made up of 60,000 images.
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dsets</span>
</code></pre></div></p>
<div class="highlight"><pre><span></span><code><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="mi">60000</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Inspecting a single image</p>
<p>So this is how a single image is represented in numbers. It's actually a 28 pixel x 28 pixel image which is why you would end up with this 28x28 matrix of numbers.
<div class="highlight"><pre><span></span><code><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="p">(</span><span class="n">tensor</span><span class="p">([[[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0118</span><span class="p">,</span>  <span class="mf">0.0706</span><span class="p">,</span>
            <span class="mf">0.0706</span><span class="p">,</span>  <span class="mf">0.0706</span><span class="p">,</span>  <span class="mf">0.4941</span><span class="p">,</span>  <span class="mf">0.5333</span><span class="p">,</span>  <span class="mf">0.6863</span><span class="p">,</span>  <span class="mf">0.1020</span><span class="p">,</span>  <span class="mf">0.6510</span><span class="p">,</span>
            <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">0.9686</span><span class="p">,</span>  <span class="mf">0.4980</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.1176</span><span class="p">,</span>  <span class="mf">0.1412</span><span class="p">,</span>  <span class="mf">0.3686</span><span class="p">,</span>  <span class="mf">0.6039</span><span class="p">,</span>  <span class="mf">0.6667</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>
            <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.8824</span><span class="p">,</span>  <span class="mf">0.6745</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>
            <span class="mf">0.9490</span><span class="p">,</span>  <span class="mf">0.7647</span><span class="p">,</span>  <span class="mf">0.2510</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.1922</span><span class="p">,</span>  <span class="mf">0.9333</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>
            <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9843</span><span class="p">,</span>  <span class="mf">0.3647</span><span class="p">,</span>  <span class="mf">0.3216</span><span class="p">,</span>  <span class="mf">0.3216</span><span class="p">,</span>
            <span class="mf">0.2196</span><span class="p">,</span>  <span class="mf">0.1529</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0706</span><span class="p">,</span>  <span class="mf">0.8588</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>
            <span class="mf">0.7765</span><span class="p">,</span>  <span class="mf">0.7137</span><span class="p">,</span>  <span class="mf">0.9686</span><span class="p">,</span>  <span class="mf">0.9451</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.3137</span><span class="p">,</span>  <span class="mf">0.6118</span><span class="p">,</span>  <span class="mf">0.4196</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.8039</span><span class="p">,</span>
            <span class="mf">0.0431</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.1686</span><span class="p">,</span>  <span class="mf">0.6039</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0549</span><span class="p">,</span>  <span class="mf">0.0039</span><span class="p">,</span>  <span class="mf">0.6039</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.3529</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.5451</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.7451</span><span class="p">,</span>
            <span class="mf">0.0078</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0431</span><span class="p">,</span>  <span class="mf">0.7451</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>
            <span class="mf">0.2745</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.1373</span><span class="p">,</span>  <span class="mf">0.9451</span><span class="p">,</span>
            <span class="mf">0.8824</span><span class="p">,</span>  <span class="mf">0.6275</span><span class="p">,</span>  <span class="mf">0.4235</span><span class="p">,</span>  <span class="mf">0.0039</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.3176</span><span class="p">,</span>
            <span class="mf">0.9412</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.4667</span><span class="p">,</span>  <span class="mf">0.0980</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.1765</span><span class="p">,</span>  <span class="mf">0.7294</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.5882</span><span class="p">,</span>  <span class="mf">0.1059</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0627</span><span class="p">,</span>  <span class="mf">0.3647</span><span class="p">,</span>  <span class="mf">0.9882</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.7333</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.9765</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9765</span><span class="p">,</span>  <span class="mf">0.2510</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.1804</span><span class="p">,</span>  <span class="mf">0.5098</span><span class="p">,</span>  <span class="mf">0.7176</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.8118</span><span class="p">,</span>  <span class="mf">0.0078</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.1529</span><span class="p">,</span>  <span class="mf">0.5804</span><span class="p">,</span>
            <span class="mf">0.8980</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9804</span><span class="p">,</span>  <span class="mf">0.7137</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0941</span><span class="p">,</span>  <span class="mf">0.4471</span><span class="p">,</span>  <span class="mf">0.8667</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>
            <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.7882</span><span class="p">,</span>  <span class="mf">0.3059</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0902</span><span class="p">,</span>  <span class="mf">0.2588</span><span class="p">,</span>  <span class="mf">0.8353</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>
            <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.7765</span><span class="p">,</span>  <span class="mf">0.3176</span><span class="p">,</span>  <span class="mf">0.0078</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0706</span><span class="p">,</span>
            <span class="mf">0.6706</span><span class="p">,</span>  <span class="mf">0.8588</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.7647</span><span class="p">,</span>
            <span class="mf">0.3137</span><span class="p">,</span>  <span class="mf">0.0353</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.2157</span><span class="p">,</span>  <span class="mf">0.6745</span><span class="p">,</span>  <span class="mf">0.8863</span><span class="p">,</span>
            <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9569</span><span class="p">,</span>  <span class="mf">0.5216</span><span class="p">,</span>  <span class="mf">0.0431</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.5333</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.9922</span><span class="p">,</span>
            <span class="mf">0.9922</span><span class="p">,</span>  <span class="mf">0.8314</span><span class="p">,</span>  <span class="mf">0.5294</span><span class="p">,</span>  <span class="mf">0.5176</span><span class="p">,</span>  <span class="mf">0.0627</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>
            <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">]]]),</span>
 <span class="n">tensor</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Inspecting a single data point in the training dataset</p>
<p>When you load MNIST dataset, each data point is actually a tuple containing the image matrix and the label.</p>
<div class="highlight"><pre><span></span><code><span class="nb">type</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="nb">tuple</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Inspecting training dataset first element of tuple</p>
<p>This means to access the image, you need to access the first element in the tuple.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Input Matrix</span>
<span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="c1"># A 28x28 sized image of a digit</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Inspecting training dataset second element of tuple</p>
<p>The second element actually represents the image's label. Meaning if the second element says 5, it means the 28x28 matrix of numbers represent a digit 5.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Label</span>
<span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">tensor</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div>
<h4 id="displaying-mnist">Displaying MNIST<a class="headerlink" href="#displaying-mnist" title="Permanent link">&para;</a></h4>
<div class="admonition note">
<p class="admonition-title">Verifying shape of MNIST image</p>
<p>As mentioned, a single MNIST image is of the shape 28 pixel x 28 pixel.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>  
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Plot image of MNIST image</p>
<div class="highlight"><pre><span></span><code><span class="n">show_img</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">show_img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</code></pre></div>
</div>
<p><img alt="png" src="../pytorch_logistic_regression_files/pytorch_logistic_regression_24_1.png" /></p>
<div class="admonition note">
<p class="admonition-title">Second element of tuple shows label</p>
<p>As you would expect, the label is 5.
<div class="highlight"><pre><span></span><code><span class="c1"># Label</span>
<span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="n">tensor</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Plot second image of MNIST image</p>
<div class="highlight"><pre><span></span><code><span class="n">show_img</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">show_img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</code></pre></div>
</div>
<p><img alt="png" src="../pytorch_logistic_regression_files/pytorch_logistic_regression_27_1.png" /></p>
<div class="admonition note">
<p class="admonition-title">Second element of tuple shows label</p>
<p>We should see 0 here as the label.
<div class="highlight"><pre><span></span><code><span class="c1"># Label</span>
<span class="n">train_dataset</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<h3 id="step-1b-loading-mnist-test-dataset">Step 1b: Loading MNIST Test Dataset<a class="headerlink" href="#step-1b-loading-mnist-test-dataset" title="Permanent link">&para;</a></h3>
<ul>
<li>Show our algorithm works beyond the data we have trained on.</li>
<li>Out-of-sample</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Load test dataset</p>
<p>Compared to the 60k images in the training set, the testing set where the model will not be trained on has 10k images to check for its out-of-sample performance.
<div class="highlight"><pre><span></span><code><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>
</code></pre></div></p>
<div class="highlight"><pre><span></span><code><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="mi">10000</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Test dataset elements</p>
<p>Exactly like the training set, the testing set has 10k tuples containing the 28x28 matrices and their respective labels.
<div class="highlight"><pre><span></span><code><span class="nb">type</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="nb">tuple</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Test dataset first element in tuple</p>
<p>This contains the image matrix, similar to the training set.
<div class="highlight"><pre><span></span><code><span class="c1"># Image matrix</span>
<span class="n">test_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Plot image sample from test dataset</p>
<div class="highlight"><pre><span></span><code><span class="n">show_img</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">show_img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</code></pre></div>
</div>
<p><img alt="png" src="../pytorch_logistic_regression_files/pytorch_logistic_regression_34_1.png" /></p>
<div class="admonition note">
<p class="admonition-title">Test dataset second element in tuple</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Label</span>
<span class="n">test_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">tensor</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
</code></pre></div>
<h3 id="step-2-make-dataset-iterable">Step 2: Make Dataset Iterable<a class="headerlink" href="#step-2-make-dataset-iterable" title="Permanent link">&para;</a></h3>
<ul>
<li>Aim: make the dataset iterable</li>
<li><strong>totaldata</strong>: 60000</li>
<li><strong>minibatch</strong>: 100<ul>
<li>Number of examples in 1 iteration</li>
</ul>
</li>
<li><strong>iterations</strong>: 3000<ul>
<li>1 iteration: one mini-batch forward &amp; backward pass</li>
</ul>
</li>
<li><strong>epochs</strong><ul>
<li>1 epoch: running through the whole dataset once</li>
<li><span class="arithmatex">\(epochs = iterations \div \frac{totaldata}{minibatch} = 3000 \div \frac{60000}{100} = 5\)</span></li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Recap training dataset</p>
<p>Remember training dataset has 60k images and testing dataset has 10k images.
<div class="highlight"><pre><span></span><code><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="mi">60000</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Defining epochs</p>
<p>When the model goes through the whole 60k images once, learning how to classify 0-9, it's consider 1 epoch. </p>
<p>However, there's a concept of batch size where it means the model would look at 100 images before updating the model's weights, thereby learning. When the model updates its weights (parameters) after looking at all the images, this is considered 1 iteration.</p>
<div class="highlight"><pre><span></span><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
</code></pre></div>
<p>We arbitrarily set 3000 iterations here which means the model would update 3000 times.
<div class="highlight"><pre><span></span><code><span class="n">n_iters</span> <span class="o">=</span> <span class="mi">3000</span>
</code></pre></div></p>
<p>One epoch consists of 60,000 / 100 = 600 iterations. Because we would like to go through 3000 iterations, this implies we would have 3000 / 600 = 5 epochs as each epoch has 600 iterations. </p>
<div class="highlight"><pre><span></span><code><span class="n">num_epochs</span> <span class="o">=</span> <span class="n">n_iters</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>
<span class="n">num_epochs</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="mi">5</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Create Iterable Object: Training Dataset</p>
<div class="highlight"><pre><span></span><code><span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Check Iterability</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">collections</span>
<span class="nb">isinstance</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">Iterable</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="kc">True</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Create Iterable Object: Testing Dataset</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Iterable object</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Check iterability of testing dataset</p>
<div class="highlight"><pre><span></span><code><span class="nb">isinstance</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">Iterable</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="kc">True</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Iterate through dataset</p>
<p>This is just a simplified example of what we're doing above where we're creating an iterable object <code>lst</code> to loop through so we can access all the images <code>img_1</code> and <code>img_2</code>.</p>
<p>Above, the equivalent of <code>lst</code> is <code>train_loader</code> and <code>test_loader</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">img_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
<span class="n">img_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
<span class="n">lst</span> <span class="o">=</span> <span class="p">[</span><span class="n">img_1</span><span class="p">,</span> <span class="n">img_2</span><span class="p">]</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># Need to iterate</span>
<span class="c1"># Think of numbers as the images</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">lst</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
</code></pre></div>
<h3 id="step-3-building-model">Step 3: Building Model<a class="headerlink" href="#step-3-building-model" title="Permanent link">&para;</a></h3>
<div class="admonition note">
<p class="admonition-title">Create model class</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Same as linear regression! </span>
<span class="k">class</span> <span class="nc">LogisticRegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogisticRegressionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div>
</div>
<h3 id="step-4-instantiate-model-class">Step 4: Instantiate Model Class<a class="headerlink" href="#step-4-instantiate-model-class" title="Permanent link">&para;</a></h3>
<ul>
<li>Input dimension: <ul>
<li>Size of image</li>
<li><span class="arithmatex">\(28 \times 28 = 784\)</span></li>
</ul>
</li>
<li>Output dimension: 10<ul>
<li>0, 1, 2, 3, 4, 5, 6, 7, 8, 9</li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Check size of dataset</p>
<p>This should be 28x28.
<div class="highlight"><pre><span></span><code><span class="c1"># Size of images</span>
<span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Instantiate model class based on input and out dimensions</p>
<p>As we're trying to classify digits 0-9 a total of 10 classes, our output dimension is 10. </p>
<p>And we're feeding the model with 28x28 images, hence our input dimension is 28x28.
<div class="highlight"><pre><span></span><code><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegressionModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
</code></pre></div></p>
</div>
<h3 id="step-5-instantiate-loss-class">Step 5: Instantiate Loss Class<a class="headerlink" href="#step-5-instantiate-loss-class" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Logistic Regression</strong>: Cross Entropy Loss<ul>
<li><em>Linear Regression: MSE</em></li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Create Cross Entry Loss Class</p>
<p>Unlike linear regression, we do not use MSE here, we need Cross Entry Loss to calculate our loss before we backpropagate and update our parameters.</p>
<div class="highlight"><pre><span></span><code><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>  
</code></pre></div>
</div>
<div class="admonition alert">
<p class="admonition-title">What happens in nn.CrossEntropyLoss()?</p>
<p>It does 2 things at the same time. </p>
<p><br /> 1. Computes softmax (logistic/softmax function)
<br /> 2. Computes cross entropy</p>
</div>
<p><img alt="" src="../images/cross_entropy_final_4.png" /></p>
<h3 id="step-6-instantiate-optimizer-class">Step 6: Instantiate Optimizer Class<a class="headerlink" href="#step-6-instantiate-optimizer-class" title="Permanent link">&para;</a></h3>
<ul>
<li>Simplified equation<ul>
<li><span class="arithmatex">\(\theta = \theta - \eta \cdot \nabla_\theta\)</span><ul>
<li><span class="arithmatex">\(\theta\)</span>: parameters (our variables)</li>
<li><span class="arithmatex">\(\eta\)</span>: learning rate (how fast we want to learn)</li>
<li><span class="arithmatex">\(\nabla_\theta\)</span>: parameters' gradients</li>
</ul>
</li>
</ul>
</li>
<li>Even simplier equation<ul>
<li><code>parameters = parameters - learning_rate * parameters_gradients</code></li>
<li><strong>At every iteration, we update our model's parameters</strong></li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Create optimizer</p>
<p>Similar to what we've covered above, this calculates the parameters' gradients and update them subsequently.
<div class="highlight"><pre><span></span><code><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>  
</code></pre></div></p>
</div>
<div class="admonition note">
<p class="admonition-title">Parameters In-Depth</p>
<p>You'll realize we have 2 sets of parameters, 10x784 which is A and 10x1 which is b in the <span class="arithmatex">\(y = AX + b\)</span> equation where X is our input of size 784.</p>
<p>We'll go into details subsequently how these parameters interact with our input to produce our 10x1 output. </p>
<div class="highlight"><pre><span></span><code><span class="c1"># Type of parameter object</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

<span class="c1"># Length of parameters</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())))</span>

<span class="c1"># FC 1 Parameters </span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="c1"># FC 1 Bias Parameters</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="o">&lt;</span><span class="n">generator</span> <span class="nb">object</span> <span class="n">Module</span><span class="o">.</span><span class="n">parameters</span> <span class="n">at</span> <span class="mh">0x7ff7c884f830</span><span class="o">&gt;</span>
<span class="mi">2</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Quick Matrix Product Review</p>
<ul>
<li>Example 1: <strong>matrix product</strong><ul>
<li><span class="arithmatex">\(A: (100, 10)\)</span></li>
<li><span class="arithmatex">\(B: (10, 1)\)</span></li>
<li><span class="arithmatex">\(A \cdot B = (100, 10) \cdot (10, 1) = (100, 1)\)</span></li>
</ul>
</li>
<li>Example 2: <strong>matrix product</strong><ul>
<li><span class="arithmatex">\(A: (50, 5)\)</span></li>
<li><span class="arithmatex">\(B: (5, 2)\)</span></li>
<li><span class="arithmatex">\(A \cdot B = (50, 5) \cdot (5, 2) = (50, 2)\)</span></li>
</ul>
</li>
<li>Example 3: <strong>element-wise addition</strong><ul>
<li><span class="arithmatex">\(A: (10, 1)\)</span></li>
<li><span class="arithmatex">\(B: (10, 1)\)</span></li>
<li><span class="arithmatex">\(A + B = (10, 1)\)</span></li>
</ul>
</li>
</ul>
</div>
<p><img alt="" src="../images/lr_params2.png" /></p>
<h3 id="step-7-train-model">Step 7: Train Model<a class="headerlink" href="#step-7-train-model" title="Permanent link">&para;</a></h3>
<div class="admonition note">
<p class="admonition-title">7 step process for training models</p>
<ul>
<li>Process <ol>
<li>Convert inputs/labels to tensors with gradients</li>
<li>Clear gradient buffets</li>
<li>Get output given inputs</li>
<li>Get loss</li>
<li>Get gradients w.r.t. parameters</li>
<li>Update parameters using gradients<ul>
<li><code>parameters = parameters - learning_rate * parameters_gradients</code></li>
</ul>
</li>
<li>REPEAT</li>
</ol>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="c1"># Load images as Variable</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>

        <span class="c1"># Clear gradients w.r.t. parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass to get output/logits</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Getting gradients w.r.t. parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updating parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate Accuracy         </span>
            <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Iterate through test dataset</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="c1"># Load images to a Torch Variable</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

                <span class="c1"># Forward pass only to get logits/output</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

                <span class="c1"># Get predictions from the maximum value</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Total number of labels</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># Total correct predictions</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

            <span class="c1"># Print Loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="s1">. Loss: </span><span class="si">{}</span><span class="s1">. Accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">Iteration</span><span class="p">:</span> <span class="mf">500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.8513233661651611</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">70</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.5732524394989014</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">77</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.3840199708938599</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">79</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.1711134910583496</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">81</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.1094708442687988</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">82</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">3000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.002761721611023</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">82</span>
</code></pre></div>
<h4 id="break-down-accuracy-calculation">Break Down Accuracy Calculation<a class="headerlink" href="#break-down-accuracy-calculation" title="Permanent link">&para;</a></h4>
<div class="admonition note">
<p class="admonition-title">Printing outputs of our model</p>
<p>As we've trained our model, we can extract the accuracy calculation portion to understand what's happening without re-training the model.</p>
<p>This would print out the output of the model's predictions on your notebook.</p>
<div class="highlight"><pre><span></span><code><span class="n">iter_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
    <span class="n">iter_test</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">iter_test</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;OUTPUTS&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">OUTPUTS</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.4181</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0784</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4840</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0985</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2394</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1801</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1639</span><span class="p">,</span>
          <span class="mf">2.9352</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1552</span><span class="p">,</span>  <span class="mf">0.8852</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.5117</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1099</span><span class="p">,</span>  <span class="mf">1.5295</span><span class="p">,</span>  <span class="mf">0.8863</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8813</span><span class="p">,</span>  <span class="mf">0.5967</span><span class="p">,</span>  <span class="mf">1.3632</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">1.8977</span><span class="p">,</span>  <span class="mf">0.4183</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4990</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.0126</span><span class="p">,</span>  <span class="mf">2.4112</span><span class="p">,</span>  <span class="mf">0.2373</span><span class="p">,</span>  <span class="mf">0.0857</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7007</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2015</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3428</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.2548</span><span class="p">,</span>  <span class="mf">0.1659</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4703</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">2.8072</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.2973</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0984</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4313</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9619</span><span class="p">,</span>  <span class="mf">0.8670</span><span class="p">,</span>  <span class="mf">1.2201</span><span class="p">,</span>
          <span class="mf">0.3752</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2873</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3272</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0343</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0043</span><span class="p">,</span>  <span class="mf">0.5081</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6452</span><span class="p">,</span>  <span class="mf">1.8647</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6924</span><span class="p">,</span>  <span class="mf">0.1435</span><span class="p">,</span>
          <span class="mf">0.4330</span><span class="p">,</span>  <span class="mf">0.2958</span><span class="p">,</span>  <span class="mf">1.0339</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.5392</span><span class="p">,</span>  <span class="mf">2.9070</span><span class="p">,</span>  <span class="mf">0.2297</span><span class="p">,</span>  <span class="mf">0.3139</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6863</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2734</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8377</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.1238</span><span class="p">,</span>  <span class="mf">0.3285</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3004</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.2037</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3739</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5947</span><span class="p">,</span>  <span class="mf">0.3530</span><span class="p">,</span>  <span class="mf">1.4205</span><span class="p">,</span>  <span class="mf">0.0593</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7307</span><span class="p">,</span>
          <span class="mf">0.6642</span><span class="p">,</span>  <span class="mf">0.3937</span><span class="p">,</span>  <span class="mf">0.8004</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.4439</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3284</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7652</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0952</span><span class="p">,</span>  <span class="mf">0.9323</span><span class="p">,</span>  <span class="mf">0.3006</span><span class="p">,</span>  <span class="mf">0.0238</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.0810</span><span class="p">,</span>  <span class="mf">0.0612</span><span class="p">,</span>  <span class="mf">1.3295</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.5409</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5266</span><span class="p">,</span>  <span class="mf">0.9914</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2369</span><span class="p">,</span>  <span class="mf">0.6583</span><span class="p">,</span>  <span class="mf">0.0992</span><span class="p">,</span>  <span class="mf">0.8525</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">1.0562</span><span class="p">,</span>  <span class="mf">0.2013</span><span class="p">,</span>  <span class="mf">0.0462</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.6548</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7253</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9825</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1663</span><span class="p">,</span>  <span class="mf">0.9076</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0694</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3708</span><span class="p">,</span>
          <span class="mf">1.8270</span><span class="p">,</span>  <span class="mf">0.2457</span><span class="p">,</span>  <span class="mf">1.5921</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">3.2147</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7689</span><span class="p">,</span>  <span class="mf">0.8531</span><span class="p">,</span>  <span class="mf">1.2320</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8126</span><span class="p">,</span>  <span class="mf">1.1251</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2776</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">1.4244</span><span class="p">,</span>  <span class="mf">0.5930</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6183</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.7470</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5545</span><span class="p">,</span>  <span class="mf">1.0251</span><span class="p">,</span>  <span class="mf">0.0529</span><span class="p">,</span>  <span class="mf">0.4384</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5934</span><span class="p">,</span>  <span class="mf">0.7666</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">1.0084</span><span class="p">,</span>  <span class="mf">0.5313</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3465</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.7916</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7064</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7805</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1588</span><span class="p">,</span>  <span class="mf">1.3284</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1708</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2092</span><span class="p">,</span>
          <span class="mf">0.9495</span><span class="p">,</span>  <span class="mf">0.1033</span><span class="p">,</span>  <span class="mf">2.0208</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">3.0602</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3578</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2576</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2198</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2372</span><span class="p">,</span>  <span class="mf">0.9765</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1514</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.5380</span><span class="p">,</span>  <span class="mf">0.7970</span><span class="p">,</span>  <span class="mf">0.1374</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.2613</span><span class="p">,</span>  <span class="mf">2.8594</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0874</span><span class="p">,</span>  <span class="mf">0.1974</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2018</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0064</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0923</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.2142</span><span class="p">,</span>  <span class="mf">0.2575</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3218</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.4348</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7216</span><span class="p">,</span>  <span class="mf">0.0021</span><span class="p">,</span>  <span class="mf">1.2864</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5062</span><span class="p">,</span>  <span class="mf">0.7761</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3236</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.5667</span><span class="p">,</span>  <span class="mf">0.5431</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7781</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.2157</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0200</span><span class="p">,</span>  <span class="mf">0.1829</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6882</span><span class="p">,</span>  <span class="mf">1.3815</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7609</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0902</span><span class="p">,</span>
          <span class="mf">0.8647</span><span class="p">,</span>  <span class="mf">0.3679</span><span class="p">,</span>  <span class="mf">1.8843</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0950</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5009</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6347</span><span class="p">,</span>  <span class="mf">0.3662</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4679</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0359</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7671</span><span class="p">,</span>
          <span class="mf">2.7155</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3991</span><span class="p">,</span>  <span class="mf">0.5737</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.7005</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5366</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0434</span><span class="p">,</span>  <span class="mf">1.1289</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5873</span><span class="p">,</span>  <span class="mf">0.2555</span><span class="p">,</span>  <span class="mf">0.8187</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.6557</span><span class="p">,</span>  <span class="mf">0.1241</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4297</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.0635</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5991</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4677</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1231</span><span class="p">,</span>  <span class="mf">2.0445</span><span class="p">,</span>  <span class="mf">0.1128</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1825</span><span class="p">,</span>
          <span class="mf">0.1075</span><span class="p">,</span>  <span class="mf">0.0348</span><span class="p">,</span>  <span class="mf">1.4317</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.0319</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1595</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3415</span><span class="p">,</span>  <span class="mf">0.1095</span><span class="p">,</span>  <span class="mf">0.5339</span><span class="p">,</span>  <span class="mf">0.1973</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3272</span><span class="p">,</span>
          <span class="mf">1.5765</span><span class="p">,</span>  <span class="mf">0.4784</span><span class="p">,</span>  <span class="mf">1.4176</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.4928</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5653</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0672</span><span class="p">,</span>  <span class="mf">0.3325</span><span class="p">,</span>  <span class="mf">0.5359</span><span class="p">,</span>  <span class="mf">0.5368</span><span class="p">,</span>  <span class="mf">2.1542</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">1.4276</span><span class="p">,</span>  <span class="mf">0.3605</span><span class="p">,</span>  <span class="mf">0.0587</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.4761</span><span class="p">,</span>  <span class="mf">0.2958</span><span class="p">,</span>  <span class="mf">0.6597</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2658</span><span class="p">,</span>  <span class="mf">1.1279</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0676</span><span class="p">,</span>  <span class="mf">1.2506</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.2059</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1489</span><span class="p">,</span>  <span class="mf">0.1051</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0764</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9274</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6838</span><span class="p">,</span>  <span class="mf">0.3464</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2656</span><span class="p">,</span>  <span class="mf">1.4099</span><span class="p">,</span>  <span class="mf">0.4486</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.9527</span><span class="p">,</span>  <span class="mf">0.5682</span><span class="p">,</span>  <span class="mf">0.0156</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.6900</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9611</span><span class="p">,</span>  <span class="mf">0.1395</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0079</span><span class="p">,</span>  <span class="mf">1.5424</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3208</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2682</span><span class="p">,</span>
          <span class="mf">0.3586</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2771</span><span class="p">,</span>  <span class="mf">1.0389</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">4.3606</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.8621</span><span class="p">,</span>  <span class="mf">0.6310</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9657</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2486</span><span class="p">,</span>  <span class="mf">1.2009</span><span class="p">,</span>  <span class="mf">1.1873</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.8255</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2103</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2172</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.1000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4268</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4627</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1041</span><span class="p">,</span>  <span class="mf">0.2959</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1392</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6855</span><span class="p">,</span>
          <span class="mf">1.8622</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2580</span><span class="p">,</span>  <span class="mf">1.1347</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.3625</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1323</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2224</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8754</span><span class="p">,</span>  <span class="mf">2.4684</span><span class="p">,</span>  <span class="mf">0.0295</span><span class="p">,</span>  <span class="mf">0.1161</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.2660</span><span class="p">,</span>  <span class="mf">0.3037</span><span class="p">,</span>  <span class="mf">1.4570</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">2.8688</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.4517</span><span class="p">,</span>  <span class="mf">0.1782</span><span class="p">,</span>  <span class="mf">1.1149</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0898</span><span class="p">,</span>  <span class="mf">1.1062</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0681</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.5697</span><span class="p">,</span>  <span class="mf">0.8888</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6965</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.0429</span><span class="p">,</span>  <span class="mf">1.4446</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3349</span><span class="p">,</span>  <span class="mf">0.1254</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5017</span><span class="p">,</span>  <span class="mf">0.2286</span><span class="p">,</span>  <span class="mf">0.2328</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.3290</span><span class="p">,</span>  <span class="mf">0.3949</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2586</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.8476</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0004</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1003</span><span class="p">,</span>  <span class="mf">2.2806</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2226</span><span class="p">,</span>  <span class="mf">0.9251</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3165</span><span class="p">,</span>
          <span class="mf">0.4957</span><span class="p">,</span>  <span class="mf">0.0690</span><span class="p">,</span>  <span class="mf">0.0232</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.9108</span><span class="p">,</span>  <span class="mf">1.1355</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2715</span><span class="p">,</span>  <span class="mf">0.2233</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3681</span><span class="p">,</span>  <span class="mf">0.1442</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0001</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.0174</span><span class="p">,</span>  <span class="mf">0.1454</span><span class="p">,</span>  <span class="mf">0.2286</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.0663</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8466</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7147</span><span class="p">,</span>  <span class="mf">2.5685</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2090</span><span class="p">,</span>  <span class="mf">1.2993</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3057</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.8314</span><span class="p">,</span>  <span class="mf">0.7046</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0176</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.7013</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8051</span><span class="p">,</span>  <span class="mf">0.7541</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5248</span><span class="p">,</span>  <span class="mf">0.8972</span><span class="p">,</span>  <span class="mf">0.1518</span><span class="p">,</span>  <span class="mf">1.4876</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.8454</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2022</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2829</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.8179</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1239</span><span class="p">,</span>  <span class="mf">0.8630</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2137</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2275</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5411</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3448</span><span class="p">,</span>
          <span class="mf">1.7354</span><span class="p">,</span>  <span class="mf">0.7751</span><span class="p">,</span>  <span class="mf">0.6234</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.6515</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0431</span><span class="p">,</span>  <span class="mf">2.7165</span><span class="p">,</span>  <span class="mf">0.1873</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0623</span><span class="p">,</span>  <span class="mf">0.1286</span><span class="p">,</span>  <span class="mf">0.3597</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.2739</span><span class="p">,</span>  <span class="mf">0.3871</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6699</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.2828</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4663</span><span class="p">,</span>  <span class="mf">0.1182</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0896</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3640</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5129</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4905</span><span class="p">,</span>
          <span class="mf">2.2914</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2227</span><span class="p">,</span>  <span class="mf">0.9463</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.2596</span><span class="p">,</span>  <span class="mf">2.0468</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4405</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0411</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8073</span><span class="p">,</span>  <span class="mf">0.0490</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0604</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.1206</span><span class="p">,</span>  <span class="mf">0.3504</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1059</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.6089</span><span class="p">,</span>  <span class="mf">0.5885</span><span class="p">,</span>  <span class="mf">0.7898</span><span class="p">,</span>  <span class="mf">1.1318</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9008</span><span class="p">,</span>  <span class="mf">0.5875</span><span class="p">,</span>  <span class="mf">0.4227</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">1.1815</span><span class="p">,</span>  <span class="mf">0.5652</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3590</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.4551</span><span class="p">,</span>  <span class="mf">2.9537</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2805</span><span class="p">,</span>  <span class="mf">0.2372</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4180</span><span class="p">,</span>  <span class="mf">0.0297</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1515</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.6111</span><span class="p">,</span>  <span class="mf">0.6140</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3354</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.7182</span><span class="p">,</span>  <span class="mf">1.6778</span><span class="p">,</span>  <span class="mf">0.0553</span><span class="p">,</span>  <span class="mf">0.0461</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5446</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0338</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0215</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.0881</span><span class="p">,</span>  <span class="mf">0.1506</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2107</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.8027</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7854</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1275</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3177</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1600</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1964</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6084</span><span class="p">,</span>
          <span class="mf">2.1285</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1815</span><span class="p">,</span>  <span class="mf">1.1911</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">2.0656</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4959</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1154</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1363</span><span class="p">,</span>  <span class="mf">2.2426</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7441</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8413</span><span class="p">,</span>
          <span class="mf">0.4675</span><span class="p">,</span>  <span class="mf">0.3269</span><span class="p">,</span>  <span class="mf">1.7279</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.3004</span><span class="p">,</span>  <span class="mf">1.0166</span><span class="p">,</span>  <span class="mf">1.1175</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0618</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0937</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4221</span><span class="p">,</span>  <span class="mf">0.1943</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">1.1020</span><span class="p">,</span>  <span class="mf">0.3670</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4683</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.0720</span><span class="p">,</span>  <span class="mf">0.2252</span><span class="p">,</span>  <span class="mf">0.0175</span><span class="p">,</span>  <span class="mf">1.3644</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7409</span><span class="p">,</span>  <span class="mf">0.4655</span><span class="p">,</span>  <span class="mf">0.5439</span><span class="p">,</span>
          <span class="mf">0.0380</span><span class="p">,</span>  <span class="mf">0.1279</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2302</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.2409</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2622</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6336</span><span class="p">,</span>  <span class="mf">1.8240</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5951</span><span class="p">,</span>  <span class="mf">1.3408</span><span class="p">,</span>  <span class="mf">0.2130</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">1.3789</span><span class="p">,</span>  <span class="mf">0.8363</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2101</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.3849</span><span class="p">,</span>  <span class="mf">0.3773</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0585</span><span class="p">,</span>  <span class="mf">0.6896</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0998</span><span class="p">,</span>  <span class="mf">0.2804</span><span class="p">,</span>  <span class="mf">0.0696</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.2529</span><span class="p">,</span>  <span class="mf">0.3143</span><span class="p">,</span>  <span class="mf">0.3409</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.9103</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1578</span><span class="p">,</span>  <span class="mf">1.6673</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4817</span><span class="p">,</span>  <span class="mf">0.4088</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5484</span><span class="p">,</span>  <span class="mf">0.6103</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.2287</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0665</span><span class="p">,</span>  <span class="mf">0.0055</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.1692</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.8531</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2499</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0257</span><span class="p">,</span>  <span class="mf">2.8580</span><span class="p">,</span>  <span class="mf">0.2616</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7122</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.0551</span><span class="p">,</span>  <span class="mf">0.8112</span><span class="p">,</span>  <span class="mf">2.3233</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.2790</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9494</span><span class="p">,</span>  <span class="mf">0.6096</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5653</span><span class="p">,</span>  <span class="mf">2.2792</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0687</span><span class="p">,</span>  <span class="mf">0.1634</span><span class="p">,</span>
          <span class="mf">0.3122</span><span class="p">,</span>  <span class="mf">0.1053</span><span class="p">,</span>  <span class="mf">1.0884</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.1267</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2297</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1315</span><span class="p">,</span>  <span class="mf">0.2428</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5436</span><span class="p">,</span>  <span class="mf">0.4123</span><span class="p">,</span>  <span class="mf">2.3060</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.9278</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1528</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4224</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0235</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9137</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1457</span><span class="p">,</span>  <span class="mf">1.6858</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7552</span><span class="p">,</span>  <span class="mf">0.7293</span><span class="p">,</span>  <span class="mf">0.2510</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.3955</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2187</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1505</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.5643</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2783</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4149</span><span class="p">,</span>  <span class="mf">0.0304</span><span class="p">,</span>  <span class="mf">0.8375</span><span class="p">,</span>  <span class="mf">1.5018</span><span class="p">,</span>  <span class="mf">0.0338</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.3875</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0117</span><span class="p">,</span>  <span class="mf">0.5751</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.2926</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7486</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3238</span><span class="p">,</span>  <span class="mf">1.0384</span><span class="p">,</span>  <span class="mf">0.0308</span><span class="p">,</span>  <span class="mf">0.6792</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0170</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.5797</span><span class="p">,</span>  <span class="mf">0.2819</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3510</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.1219</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5862</span><span class="p">,</span>  <span class="mf">1.5817</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1297</span><span class="p">,</span>  <span class="mf">0.4730</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9171</span><span class="p">,</span>  <span class="mf">0.7886</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.7022</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0501</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2812</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.7587</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.4511</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7369</span><span class="p">,</span>  <span class="mf">0.4082</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6426</span><span class="p">,</span>  <span class="mf">1.1784</span><span class="p">,</span>  <span class="mf">0.6052</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.7178</span><span class="p">,</span>  <span class="mf">1.6161</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2220</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.1267</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.6719</span><span class="p">,</span>  <span class="mf">0.0505</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4972</span><span class="p">,</span>  <span class="mf">2.9027</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1461</span><span class="p">,</span>  <span class="mf">0.2807</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.2921</span><span class="p">,</span>  <span class="mf">0.2231</span><span class="p">,</span>  <span class="mf">1.1327</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.9892</span><span class="p">,</span>  <span class="mf">2.4401</span><span class="p">,</span>  <span class="mf">0.1274</span><span class="p">,</span>  <span class="mf">0.2838</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7535</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1684</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6493</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.1908</span><span class="p">,</span>  <span class="mf">0.2290</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2150</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.2071</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1351</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9191</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9309</span><span class="p">,</span>  <span class="mf">1.7747</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3046</span><span class="p">,</span>  <span class="mf">0.0183</span><span class="p">,</span>
          <span class="mf">1.0136</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1016</span><span class="p">,</span>  <span class="mf">2.1288</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0103</span><span class="p">,</span>  <span class="mf">0.3280</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6974</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2504</span><span class="p">,</span>  <span class="mf">0.3187</span><span class="p">,</span>  <span class="mf">0.4390</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1879</span><span class="p">,</span>
          <span class="mf">0.3954</span><span class="p">,</span>  <span class="mf">0.2332</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1971</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.2280</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6754</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7438</span><span class="p">,</span>  <span class="mf">0.5078</span><span class="p">,</span>  <span class="mf">0.2544</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1020</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2503</span><span class="p">,</span>
          <span class="mf">2.0799</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5033</span><span class="p">,</span>  <span class="mf">0.5890</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.3972</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9369</span><span class="p">,</span>  <span class="mf">1.2696</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6713</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4159</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0221</span><span class="p">,</span>  <span class="mf">0.6489</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.4777</span><span class="p">,</span>  <span class="mf">1.2497</span><span class="p">,</span>  <span class="mf">0.3931</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.7566</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8230</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0785</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3083</span><span class="p">,</span>  <span class="mf">0.7821</span><span class="p">,</span>  <span class="mf">0.1880</span><span class="p">,</span>  <span class="mf">0.1037</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.0956</span><span class="p">,</span>  <span class="mf">0.4219</span><span class="p">,</span>  <span class="mf">1.0798</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.0328</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1700</span><span class="p">,</span>  <span class="mf">1.3806</span><span class="p">,</span>  <span class="mf">0.5445</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2624</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0780</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3595</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.6253</span><span class="p">,</span>  <span class="mf">0.4309</span><span class="p">,</span>  <span class="mf">0.1813</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.0360</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4704</span><span class="p">,</span>  <span class="mf">0.1948</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7066</span><span class="p">,</span>  <span class="mf">0.6600</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4633</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3602</span><span class="p">,</span>
          <span class="mf">1.7494</span><span class="p">,</span>  <span class="mf">0.1522</span><span class="p">,</span>  <span class="mf">0.6086</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.2032</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7903</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5754</span><span class="p">,</span>  <span class="mf">0.4722</span><span class="p">,</span>  <span class="mf">0.6068</span><span class="p">,</span>  <span class="mf">0.5752</span><span class="p">,</span>  <span class="mf">0.2151</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.2495</span><span class="p">,</span>  <span class="mf">0.3420</span><span class="p">,</span>  <span class="mf">0.9278</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.2247</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1361</span><span class="p">,</span>  <span class="mf">0.9374</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1543</span><span class="p">,</span>  <span class="mf">0.4921</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6553</span><span class="p">,</span>  <span class="mf">0.5885</span><span class="p">,</span>
          <span class="mf">0.2617</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2216</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3736</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.2867</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4486</span><span class="p">,</span>  <span class="mf">0.6658</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8755</span><span class="p">,</span>  <span class="mf">2.3195</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7627</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2132</span><span class="p">,</span>
          <span class="mf">0.2488</span><span class="p">,</span>  <span class="mf">0.3484</span><span class="p">,</span>  <span class="mf">1.0860</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.4031</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4518</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3181</span><span class="p">,</span>  <span class="mf">2.8268</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5371</span><span class="p">,</span>  <span class="mf">1.0154</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9247</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.7385</span><span class="p">,</span>  <span class="mf">1.1031</span><span class="p">,</span>  <span class="mf">0.0422</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">2.8604</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5413</span><span class="p">,</span>  <span class="mf">0.6241</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8017</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4104</span><span class="p">,</span>  <span class="mf">0.6314</span><span class="p">,</span>  <span class="mf">0.4614</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.0218</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3411</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2609</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.2113</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2348</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8535</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1041</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2703</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1294</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7057</span><span class="p">,</span>
          <span class="mf">2.7552</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4429</span><span class="p">,</span>  <span class="mf">0.4517</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">4.5191</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.7407</span><span class="p">,</span>  <span class="mf">1.1091</span><span class="p">,</span>  <span class="mf">0.3975</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9456</span><span class="p">,</span>  <span class="mf">1.2277</span><span class="p">,</span>  <span class="mf">0.3616</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">1.6564</span><span class="p">,</span>  <span class="mf">0.5063</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4274</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.4615</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0765</span><span class="p">,</span>  <span class="mf">1.8388</span><span class="p">,</span>  <span class="mf">1.5006</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2351</span><span class="p">,</span>  <span class="mf">0.2781</span><span class="p">,</span>  <span class="mf">0.2830</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.8491</span><span class="p">,</span>  <span class="mf">0.2222</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7779</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.2160</span><span class="p">,</span>  <span class="mf">0.8502</span><span class="p">,</span>  <span class="mf">0.2413</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0798</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7880</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4286</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8060</span><span class="p">,</span>
          <span class="mf">0.7194</span><span class="p">,</span>  <span class="mf">1.2663</span><span class="p">,</span>  <span class="mf">0.6412</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.3318</span><span class="p">,</span>  <span class="mf">2.3388</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4003</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1094</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0285</span><span class="p">,</span>  <span class="mf">0.1021</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0388</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.0497</span><span class="p">,</span>  <span class="mf">0.5137</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2507</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.7853</span><span class="p">,</span>  <span class="mf">0.5884</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6108</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5557</span><span class="p">,</span>  <span class="mf">0.8696</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6226</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7983</span><span class="p">,</span>
          <span class="mf">1.7169</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0145</span><span class="p">,</span>  <span class="mf">0.8231</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.1739</span><span class="p">,</span>  <span class="mf">0.1562</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2933</span><span class="p">,</span>  <span class="mf">2.3195</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9480</span><span class="p">,</span>  <span class="mf">1.2019</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4834</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">1.0567</span><span class="p">,</span>  <span class="mf">0.5685</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6841</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.7920</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3339</span><span class="p">,</span>  <span class="mf">0.7452</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6529</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3307</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6092</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0950</span><span class="p">,</span>
          <span class="mf">1.7311</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3481</span><span class="p">,</span>  <span class="mf">0.3801</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.7810</span><span class="p">,</span>  <span class="mf">1.0676</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7611</span><span class="p">,</span>  <span class="mf">0.3658</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0431</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1012</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6048</span><span class="p">,</span>
          <span class="mf">0.3089</span><span class="p">,</span>  <span class="mf">0.9998</span><span class="p">,</span>  <span class="mf">0.7164</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.5856</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5261</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4859</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0551</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1838</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2144</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2599</span><span class="p">,</span>
          <span class="mf">3.3891</span><span class="p">,</span>  <span class="mf">0.4691</span><span class="p">,</span>  <span class="mf">0.7566</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.4984</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7770</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1998</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1075</span><span class="p">,</span>  <span class="mf">1.0882</span><span class="p">,</span>  <span class="mf">0.4539</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5651</span><span class="p">,</span>
          <span class="mf">1.4381</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5678</span><span class="p">,</span>  <span class="mf">1.7479</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.2938</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8536</span><span class="p">,</span>  <span class="mf">0.4259</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5429</span><span class="p">,</span>  <span class="mf">0.0066</span><span class="p">,</span>  <span class="mf">0.4120</span><span class="p">,</span>  <span class="mf">2.3793</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.3666</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2604</span><span class="p">,</span>  <span class="mf">0.0382</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.4080</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9851</span><span class="p">,</span>  <span class="mf">4.0264</span><span class="p">,</span>  <span class="mf">0.1099</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1766</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1557</span><span class="p">,</span>  <span class="mf">0.6419</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.8147</span><span class="p">,</span>  <span class="mf">0.7535</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1452</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.4636</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7323</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6433</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0274</span><span class="p">,</span>  <span class="mf">0.7227</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1799</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9336</span><span class="p">,</span>
          <span class="mf">2.1881</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2073</span><span class="p">,</span>  <span class="mf">1.6522</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.9617</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0348</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3980</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4738</span><span class="p">,</span>  <span class="mf">0.7790</span><span class="p">,</span>  <span class="mf">0.4671</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6115</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.7067</span><span class="p">,</span>  <span class="mf">1.3036</span><span class="p">,</span>  <span class="mf">0.4923</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.0151</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.5385</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6072</span><span class="p">,</span>  <span class="mf">0.2902</span><span class="p">,</span>  <span class="mf">3.1570</span><span class="p">,</span>  <span class="mf">0.1062</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2169</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.4491</span><span class="p">,</span>  <span class="mf">0.6326</span><span class="p">,</span>  <span class="mf">1.6829</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.8852</span><span class="p">,</span>  <span class="mf">0.6066</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2840</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4475</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1147</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7858</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1805</span><span class="p">,</span>
          <span class="mf">3.0723</span><span class="p">,</span>  <span class="mf">0.3960</span><span class="p">,</span>  <span class="mf">0.9720</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0344</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4878</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9675</span><span class="p">,</span>  <span class="mf">1.9649</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3146</span><span class="p">,</span>  <span class="mf">1.2183</span><span class="p">,</span>  <span class="mf">0.6730</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.3650</span><span class="p">,</span>  <span class="mf">0.0646</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0898</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.2118</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0350</span><span class="p">,</span>  <span class="mf">0.9917</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8993</span><span class="p">,</span>  <span class="mf">1.2334</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6723</span><span class="p">,</span>  <span class="mf">2.5847</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.0454</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4149</span><span class="p">,</span>  <span class="mf">0.3927</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.7365</span><span class="p">,</span>  <span class="mf">3.0447</span><span class="p">,</span>  <span class="mf">0.5115</span><span class="p">,</span>  <span class="mf">0.0786</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7544</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2158</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4876</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.2891</span><span class="p">,</span>  <span class="mf">0.5089</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6719</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.3652</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5457</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1167</span><span class="p">,</span>  <span class="mf">2.9056</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1622</span><span class="p">,</span>  <span class="mf">0.8192</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3245</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.6414</span><span class="p">,</span>  <span class="mf">0.8097</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4958</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.8755</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6983</span><span class="p">,</span>  <span class="mf">0.2208</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6463</span><span class="p">,</span>  <span class="mf">0.5276</span><span class="p">,</span>  <span class="mf">0.1145</span><span class="p">,</span>  <span class="mf">2.7229</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">1.0316</span><span class="p">,</span>  <span class="mf">0.1905</span><span class="p">,</span>  <span class="mf">0.2090</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.9702</span><span class="p">,</span>  <span class="mf">0.1265</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0007</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5106</span><span class="p">,</span>  <span class="mf">0.4970</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0804</span><span class="p">,</span>  <span class="mf">0.0017</span><span class="p">,</span>
          <span class="mf">0.0607</span><span class="p">,</span>  <span class="mf">0.6164</span><span class="p">,</span>  <span class="mf">0.4490</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.8271</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6822</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7434</span><span class="p">,</span>  <span class="mf">2.6457</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6143</span><span class="p">,</span>  <span class="mf">1.1486</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0705</span><span class="p">,</span>
          <span class="mf">0.5611</span><span class="p">,</span>  <span class="mf">0.6422</span><span class="p">,</span>  <span class="mf">0.1250</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.9979</span><span class="p">,</span>  <span class="mf">1.8175</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1658</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0343</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6292</span><span class="p">,</span>  <span class="mf">0.1774</span><span class="p">,</span>  <span class="mf">0.3150</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.4633</span><span class="p">,</span>  <span class="mf">0.9266</span><span class="p">,</span>  <span class="mf">0.0252</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.9039</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6030</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2173</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1768</span><span class="p">,</span>  <span class="mf">2.3198</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5072</span><span class="p">,</span>  <span class="mf">0.3418</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.1551</span><span class="p">,</span>  <span class="mf">0.1282</span><span class="p">,</span>  <span class="mf">1.4250</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.9891</span><span class="p">,</span>  <span class="mf">0.5212</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4518</span><span class="p">,</span>  <span class="mf">0.3267</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0759</span><span class="p">,</span>  <span class="mf">0.3826</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0341</span><span class="p">,</span>
          <span class="mf">0.0382</span><span class="p">,</span>  <span class="mf">0.2451</span><span class="p">,</span>  <span class="mf">0.3658</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">2.1217</span><span class="p">,</span>  <span class="mf">1.5102</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7828</span><span class="p">,</span>  <span class="mf">0.3554</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4192</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0772</span><span class="p">,</span>  <span class="mf">0.0578</span><span class="p">,</span>
          <span class="mf">0.8070</span><span class="p">,</span>  <span class="mf">0.1701</span><span class="p">,</span>  <span class="mf">0.5880</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.0665</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3826</span><span class="p">,</span>  <span class="mf">0.6243</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8096</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4227</span><span class="p">,</span>  <span class="mf">0.5925</span><span class="p">,</span>  <span class="mf">1.8112</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.9946</span><span class="p">,</span>  <span class="mf">0.2010</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7731</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.1263</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7484</span><span class="p">,</span>  <span class="mf">0.0041</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5439</span><span class="p">,</span>  <span class="mf">1.7242</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9475</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3835</span><span class="p">,</span>
          <span class="mf">0.8452</span><span class="p">,</span>  <span class="mf">0.3077</span><span class="p">,</span>  <span class="mf">2.2689</span><span class="p">]])</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Printing output size</p>
<p>This produces a 100x10 matrix because each iteration has a batch size of 100 and each prediction across the 10 classes, with the largest number indicating the likely number it is predicting.
<div class="highlight"><pre><span></span><code><span class="n">iter_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
    <span class="n">iter_test</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">iter_test</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;OUTPUTS&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="n">OUTPUTS</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Printing one output</p>
<p>This would be a 1x10 matrix where the largest number is what the model thinks the image is. Here we can see that in the tensor, position 7 has the largest number, indicating the model thinks the image is 7.</p>
<p>number 0: -0.4181
<br /> number 1: -1.0784
<br />...
<br /> number 7: 2.9352
<div class="highlight"><pre><span></span><code><span class="n">iter_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
    <span class="n">iter_test</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">iter_test</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;OUTPUTS&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code>OUTPUTS
tensor([-0.4181, -1.0784, -0.4840, -0.0985, -0.2394, -0.1801, -1.1639,
         2.9352, -0.1552,  0.8852])
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Printing prediction output</p>
<p>Because our output is of size 100 (our batch size), our prediction size would also of the size 100.</p>
<div class="highlight"><pre><span></span><code><span class="n">iter_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
    <span class="n">iter_test</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">iter_test</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;PREDICTION&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">predicted</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">PREDICTION</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Print prediction value</p>
<p>We are printing our prediction which as verified above, should be digit 7.</p>
<div class="highlight"><pre><span></span><code><span class="n">iter_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
    <span class="n">iter_test</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">iter_test</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;PREDICTION&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">predicted</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">PREDICTION</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Print prediction, label and label size</p>
<p>We are trying to show what we are predicting and the actual values. In this case, we're predicting the right value 7!</p>
<div class="highlight"><pre><span></span><code><span class="n">iter_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
    <span class="n">iter_test</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">iter_test</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;PREDICTION&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">predicted</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;LABEL SIZE&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;LABEL FOR IMAGE 0&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">PREDICTION</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>

<span class="n">LABEL</span> <span class="n">SIZE</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>

<span class="n">LABEL</span> <span class="n">FOR</span> <span class="n">IMAGE</span> <span class="mi">0</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Print second prediction and ground truth</p>
<p>Again, the prediction is correct. Naturally, as our model is quite competent in this simple task.</p>
<div class="highlight"><pre><span></span><code><span class="n">iter_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
    <span class="n">iter_test</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">iter_test</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;PREDICTION&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">predicted</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;LABEL SIZE&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;LABEL FOR IMAGE 1&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">PREDICTION</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">LABEL</span> <span class="n">SIZE</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>

<span class="n">LABEL</span> <span class="n">FOR</span> <span class="n">IMAGE</span> <span class="mi">1</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Print accuracy</p>
<p>Now we know what each object represents, we can understand how we arrived at our accuracy numbers.</p>
<p>One last thing to note is that <code>correct.item()</code> has this syntax is because <code>correct</code> is a PyTorch tensor and to get the value to compute with <code>total</code> which is an integer, we need to do this.
<div class="highlight"><pre><span></span><code><span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">iter_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
    <span class="n">iter_test</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Total number of labels</span>
    <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Total correct predictions</span>
    <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="p">(</span><span class="n">correct</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="mf">82.94</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Explanation of Python's .sum() function</p>
<p>Python's .sum() function allows you to do a comparison between two matrices and sum the ones that return <code>True</code> or in our case, those predictions that match actual labels (correct predictions).</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Explaining .sum() python built-in function</span>
<span class="c1"># correct += (predicted == labels).sum()</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">10</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">10</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">a</span> <span class="o">==</span> <span class="n">b</span><span class="p">)</span>

<span class="nb">print</span><span class="p">((</span><span class="n">a</span> <span class="o">==</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="c1"># matrix a</span>
<span class="p">[</span><span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span><span class="p">]</span>

<span class="c1"># matrix b</span>
<span class="p">[</span><span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span><span class="p">]</span>

<span class="c1"># boolean array</span>
<span class="p">[</span> <span class="kc">True</span>  <span class="kc">True</span>  <span class="kc">True</span>  <span class="kc">True</span>  <span class="kc">True</span>  <span class="kc">True</span>  <span class="kc">True</span>  <span class="kc">True</span>  <span class="kc">True</span>  <span class="kc">True</span><span class="p">]</span>

<span class="c1"># number of elementswhere a matches b</span>
<span class="mi">10</span>
</code></pre></div>
<h4 id="saving-model">Saving Model<a class="headerlink" href="#saving-model" title="Permanent link">&para;</a></h4>
<div class="admonition note">
<p class="admonition-title">Saving PyTorch model</p>
<p>This is how you save your model. Feel free to just change <code>save_model = True</code> to save your model
<div class="highlight"><pre><span></span><code><span class="n">save_model</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="n">save_model</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
    <span class="c1"># Saves only parameters</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;awesome_model.pkl&#39;</span><span class="p">)</span>
</code></pre></div></p>
</div>
<h2 id="building-a-logistic-regression-model-with-pytorch-gpu">Building a Logistic Regression Model with PyTorch (GPU)<a class="headerlink" href="#building-a-logistic-regression-model-with-pytorch-gpu" title="Permanent link">&para;</a></h2>
<div class="admonition note">
<p class="admonition-title">CPU version</p>
<p>The usual 7-step process, getting repetitive by now which we like. </p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dsets</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 1: LOADING DATASET</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 2: MAKING DATASET ITERABLE</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="n">n_iters</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 3: CREATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="k">class</span> <span class="nc">LogisticRegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogisticRegressionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 4: INSTANTIATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegressionModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 5: INSTANTIATE LOSS CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>


<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 7: TRAIN THE MODEL</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="c1"># Load images as Variable</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>

        <span class="c1"># Clear gradients w.r.t. parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass to get output/logits</span>
        <span class="c1"># 100 x 10</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Getting gradients w.r.t. parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updating parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate Accuracy         </span>
            <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Iterate through test dataset</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="c1"># Load images to a Torch Variable</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

                <span class="c1"># Forward pass only to get logits/output</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

                <span class="c1"># Get predictions from the maximum value</span>
                <span class="c1"># 100 x 1</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Total number of labels</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># Total correct predictions</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">total</span>

            <span class="c1"># Print Loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="s1">. Loss: </span><span class="si">{}</span><span class="s1">. Accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">Iteration</span><span class="p">:</span> <span class="mf">500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.876196026802063</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">64.44</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.5153584480285645</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">75.68</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.3521136045455933</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">78.98</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.2136967182159424</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">80.95</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.0934826135635376</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">81.97</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">3000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.024120569229126</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">82.49</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">GPU version</p>
<p>2 things must be on GPU
<br />- <code>model</code>
<br />- <code>tensors</code></p>
<p>Remember step 4 and 7 will be affected and this will be the same for all model building moving forward.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dsets</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 1: LOADING DATASET</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 2: MAKING DATASET ITERABLE</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="n">n_iters</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 3: CREATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="k">class</span> <span class="nc">LogisticRegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogisticRegressionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 4: INSTANTIATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegressionModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

<span class="c1">#######################</span>
<span class="c1">#  USE GPU FOR MODEL  #</span>
<span class="c1">#######################</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 5: INSTANTIATE LOSS CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>


<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 7: TRAIN THE MODEL</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>

        <span class="c1">#######################</span>
        <span class="c1">#  USE GPU FOR MODEL  #</span>
        <span class="c1">#######################</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Clear gradients w.r.t. parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass to get output/logits</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Getting gradients w.r.t. parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updating parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate Accuracy         </span>
            <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Iterate through test dataset</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="c1">#######################</span>
                <span class="c1">#  USE GPU FOR MODEL  #</span>
                <span class="c1">#######################</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># Forward pass only to get logits/output</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

                <span class="c1"># Get predictions from the maximum value</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Total number of labels</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1">#######################</span>
                <span class="c1">#  USE GPU FOR MODEL  #</span>
                <span class="c1">#######################</span>
                <span class="c1"># Total correct predictions</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                    <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="o">==</span> <span class="n">labels</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">total</span>

            <span class="c1"># Print Loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="s1">. Loss: </span><span class="si">{}</span><span class="s1">. Accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">Iteration</span><span class="p">:</span> <span class="mf">500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.8571407794952393</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">68.99</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.5415704250335693</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">75.86</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.2755383253097534</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">78.92</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.2468739748001099</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">80.72</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.0708973407745361</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">81.73</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">3000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.0359245538711548</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">82.74</span>
</code></pre></div>
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h2>
<p>We've learnt to...</p>
<div class="admonition success">
<p class="admonition-title">Success</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Logistic regression</strong> basics</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Problems</strong> of <strong>linear regression</strong></li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>In-depth</strong> Logistic Regression<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Get logits</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Get softmax</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Get cross-entropy loss</li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Aim</strong>: reduce cross-entropy loss</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Built a <strong>logistic regression model</strong> in <strong>CPU and GPU</strong><ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 1: Load Dataset</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 2: Make Dataset Iterable</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 3: Create Model Class</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 4: Instantiate Model Class</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 5: Instantiate Loss Class</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 6: Instantiate Optimizer Class</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 7: Train Model</li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Important things to be on <strong>GPU</strong><ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <code>model</code></li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <code>tensors with gradients</code></li>
</ul>
</li>
</ul>
</div>
<h2 id="citation">Citation<a class="headerlink" href="#citation" title="Permanent link">&para;</a></h2>
<p>If you have found these useful in your research, presentations, school work, projects or workshops, feel free to cite using this DOI.</p>
<p><a href="https://zenodo.org/badge/latestdoi/139945544"><img alt="DOI" src="https://zenodo.org/badge/139945544.svg" /></a></p>







  
  



  




  <h2 id="__comments">Comments</h2>
  <!-- Insert generated snippet here -->
  <script src="https://giscus.app/client.js"
        data-repo="ritchieng/deep-learning-wizard"
        data-repo-id="MDEwOlJlcG9zaXRvcnkxMzk5NDU1NDQ="
        data-category="Website"
        data-category-id="DIC_kwDOCFdmSM4Cd3O2"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="preferred_color_scheme"
        data-lang="en"
        crossorigin="anonymous"
        async>
  </script>
  <!-- Synchronize Giscus theme with palette -->
  <script>
    var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
      var theme = palette.color.scheme === "slate"
        ? "transparent_dark"
        : "light"

      // Instruct Giscus to set theme
      giscus.setAttribute("data-theme", theme) 
    }

    // Register event handlers after documented loaded
    document.addEventListener("DOMContentLoaded", function() {
      var ref = document.querySelector("[data-md-component=palette]")
      ref.addEventListener("change", function() {
        var palette = __md_get("__palette")
        if (palette && typeof palette.color === "object") {
          var theme = palette.color.scheme === "slate"
            ? "transparent_dark"
            : "light"

          // Instruct Giscus to change theme
          var frame = document.querySelector(".giscus-frame")
          frame.contentWindow.postMessage(
            { giscus: { setConfig: { theme } } },
            "https://giscus.app"
          )
        }
      })
    })
  </script>

                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../pytorch_linear_regression/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Linear Regression">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Linear Regression
              </div>
            </div>
          </a>
        
        
          
          <a href="../pytorch_feedforward_neuralnetwork/" class="md-footer__link md-footer__link--next" aria-label="Next: Feedforward Neural Networks (FNN)">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Feedforward Neural Networks (FNN)
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2018-2024 Deep Learning Wizard by Ritchie Ng
    </div>
  
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://www.youtube.com/channel/UCJz2MIjiCosOQCwhnsYxeEw" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/deeplearningwiz" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.facebook.com/DeepLearningWizard/" target="_blank" rel="noopener" title="www.facebook.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256c0 120 82.7 220.8 194.2 248.5V334.2h-52.8V256h52.8v-33.7c0-87.1 39.4-127.5 125-127.5 16.2 0 44.2 3.2 55.7 6.4V172c-6-.6-16.5-1-29.6-1-42 0-58.2 15.9-58.2 57.2V256h83.6l-14.4 78.2H287v175.9C413.8 494.8 512 386.9 512 256z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/company/deeplearningwizard/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/ritchieng" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.annotate", "content.tabs.link", "content.code.copy", "content.action.edit", "content.action.view", "navigation.sections", "navigation.tabs", "navigation.footer", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
  
      <script src="../../../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  <script src="../../../assets/javascripts/custom.129bd6ad.min.js"></script>

  </body>
</html>