
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="We try to make learning deep learning, deep bayesian learning, and deep reinforcement learning math and code easier. Used by thousands.">
      
      
      
        <meta name="author" content="Ritchie Ng">
      
      
        <link rel="canonical" href="https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_recurrent_neuralnetwork/">
      
      <link rel="icon" href="../../../docs/assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-7.2.4">
    
    
      
        <title>Recurrent Neural Networks (RNN) - Deep Learning Wizard</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.f7f47774.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.3f5d1f46.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
    
      

  


  

  


  <script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-122083328-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){var e;this.value&&(e=document.location.pathname,ga("send","pageview",e+"?q="+this.value))}),"undefined"!=typeof location$&&location$.subscribe(function(e){ga("send","pageview",e.pathname)})})</script>
  <script async src="https://www.google-analytics.com/analytics.js"></script>


    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <script>function __prefix(e){return new URL("../../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
      <script>var palette=__get("__palette");if(null!==palette&&"object"==typeof palette.color)for(var key in palette.color)document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#recurrent-neural-network-with-pytorch" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Deep Learning Wizard" class="md-header__button md-logo" aria-label="Deep Learning Wizard" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M396.8 352h22.4c6.4 0 12.8-6.4 12.8-12.8V108.8c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v230.4c0 6.4 6.4 12.8 12.8 12.8zm-192 0h22.4c6.4 0 12.8-6.4 12.8-12.8V140.8c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v198.4c0 6.4 6.4 12.8 12.8 12.8zm96 0h22.4c6.4 0 12.8-6.4 12.8-12.8V204.8c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v134.4c0 6.4 6.4 12.8 12.8 12.8zM496 400H48V80c0-8.84-7.16-16-16-16H16C7.16 64 0 71.16 0 80v336c0 17.67 14.33 32 32 32h464c8.84 0 16-7.16 16-16v-16c0-8.84-7.16-16-16-16zm-387.2-48h22.4c6.4 0 12.8-6.4 12.8-12.8v-70.4c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v70.4c0 6.4 6.4 12.8 12.8 12.8z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Deep Learning Wizard
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Recurrent Neural Networks (RNN)
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M7 10a2 2 0 0 1 2 2 2 2 0 0 1-2 2 2 2 0 0 1-2-2 2 2 0 0 1 2-2m10-3a5 5 0 0 1 5 5 5 5 0 0 1-5 5H7a5 5 0 0 1-5-5 5 5 0 0 1 5-5h10M7 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3h10a3 3 0 0 0 3-3 3 3 0 0 0-3-3H7z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3z"/></svg>
            </label>
          
        
      </form>
    
    
    
    
      <div class="md-header__source">
        
<a href="https://github.com/ritchieng/deep-learning-wizard" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ritchieng/deep-learning-wizard
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../.." class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../home/" class="md-tabs__link">
        About
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../intro/" class="md-tabs__link md-tabs__link--active">
        Deep Learning (CPU/GPU)
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../machine_learning/intro/" class="md-tabs__link">
        Machine Learning (CPU/GPU)
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../programming/intro/" class="md-tabs__link">
        Programming
      </a>
    </li>
  

      
        
  
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../data_engineering/nosql/cassandra/intro/" class="md-tabs__link">
        Data Engineering
      </a>
    </li>
  

  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../news/news/" class="md-tabs__link">
        News
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Deep Learning Wizard" class="md-nav__button md-logo" aria-label="Deep Learning Wizard" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M396.8 352h22.4c6.4 0 12.8-6.4 12.8-12.8V108.8c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v230.4c0 6.4 6.4 12.8 12.8 12.8zm-192 0h22.4c6.4 0 12.8-6.4 12.8-12.8V140.8c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v198.4c0 6.4 6.4 12.8 12.8 12.8zm96 0h22.4c6.4 0 12.8-6.4 12.8-12.8V204.8c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v134.4c0 6.4 6.4 12.8 12.8 12.8zM496 400H48V80c0-8.84-7.16-16-16-16H16C7.16 64 0 71.16 0 80v336c0 17.67 14.33 32 32 32h464c8.84 0 16-7.16 16-16v-16c0-8.84-7.16-16-16-16zm-387.2-48h22.4c6.4 0 12.8-6.4 12.8-12.8v-70.4c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v70.4c0 6.4 6.4 12.8 12.8 12.8z"/></svg>

    </a>
    Deep Learning Wizard
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/ritchieng/deep-learning-wizard" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ritchieng/deep-learning-wizard
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      <label class="md-nav__link" for="__nav_2">
        About
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="About" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          About
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../home/" class="md-nav__link">
        Intro
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../about/" class="md-nav__link">
        About Us
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../review/" class="md-nav__link">
        Reviews
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../consultancy/" class="md-nav__link">
        Consultancy
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      <label class="md-nav__link" for="__nav_3">
        Deep Learning (CPU/GPU)
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Deep Learning (CPU/GPU)" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Deep Learning (CPU/GPU)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../intro/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../course_progression/" class="md-nav__link">
        Course Progression
      </a>
    </li>
  

          
            
  
  
    
  
  
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_3" type="checkbox" id="__nav_3_3" checked>
      
      <label class="md-nav__link" for="__nav_3_3">
        Practical Deep Learning with PyTorch
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Practical Deep Learning with PyTorch" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_3">
          <span class="md-nav__icon md-icon"></span>
          Practical Deep Learning with PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_matrices/" class="md-nav__link">
        Matrices
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_gradients/" class="md-nav__link">
        Gradients
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_linear_regression/" class="md-nav__link">
        Linear Regression
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_logistic_regression/" class="md-nav__link">
        Logistic Regression
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_feedforward_neuralnetwork/" class="md-nav__link">
        Feedforward Neural Networks (FNN)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_convolutional_neuralnetwork/" class="md-nav__link">
        Convolutional Neural Networks (CNN)
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Recurrent Neural Networks (RNN)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Recurrent Neural Networks (RNN)
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#about-recurrent-neural-network" class="md-nav__link">
    About Recurrent Neural Network
  </a>
  
    <nav class="md-nav" aria-label="About Recurrent Neural Network">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#feedforward-neural-networks-transition-to-1-layer-recurrent-neural-networks-rnn" class="md-nav__link">
    Feedforward Neural Networks Transition to 1 Layer Recurrent Neural Networks (RNN)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-layer-rnn-breakdown" class="md-nav__link">
    2 Layer RNN Breakdown
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-a-recurrent-neural-network-with-pytorch" class="md-nav__link">
    Building a Recurrent Neural Network with PyTorch
  </a>
  
    <nav class="md-nav" aria-label="Building a Recurrent Neural Network with PyTorch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-a-1-hidden-layer-relu" class="md-nav__link">
    Model A: 1 Hidden Layer (ReLU)
  </a>
  
    <nav class="md-nav" aria-label="Model A: 1 Hidden Layer (ReLU)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#steps" class="md-nav__link">
    Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1-loading-mnist-train-dataset" class="md-nav__link">
    Step 1: Loading MNIST Train Dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-make-dataset-iterable" class="md-nav__link">
    Step 2: Make Dataset Iterable
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-create-model-class" class="md-nav__link">
    Step 3: Create Model Class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-instantiate-model-class" class="md-nav__link">
    Step 4: Instantiate Model Class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-5-instantiate-loss-class" class="md-nav__link">
    Step 5: Instantiate Loss Class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-6-instantiate-optimizer-class" class="md-nav__link">
    Step 6: Instantiate Optimizer Class
  </a>
  
    <nav class="md-nav" aria-label="Step 6: Instantiate Optimizer Class">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters-in-depth" class="md-nav__link">
    Parameters In-Depth
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-7-train-model" class="md-nav__link">
    Step 7: Train Model
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-b-2-hidden-layer-relu" class="md-nav__link">
    Model B: 2 Hidden Layer (ReLU)
  </a>
  
    <nav class="md-nav" aria-label="Model B: 2 Hidden Layer (ReLU)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#steps_1" class="md-nav__link">
    Steps
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-c-2-hidden-layer" class="md-nav__link">
    Model C: 2 Hidden Layer
  </a>
  
    <nav class="md-nav" aria-label="Model C: 2 Hidden Layer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#steps_2" class="md-nav__link">
    Steps
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-of-results" class="md-nav__link">
    Summary of Results
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#general-deep-learning-notes" class="md-nav__link">
    General Deep Learning Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-building-a-recurrent-neural-network-with-pytorch-gpu" class="md-nav__link">
    3. Building a Recurrent Neural Network with PyTorch (GPU)
  </a>
  
    <nav class="md-nav" aria-label="3. Building a Recurrent Neural Network with PyTorch (GPU)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-c-2-hidden-layer-tanh" class="md-nav__link">
    Model C: 2 Hidden Layer (Tanh)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steps_3" class="md-nav__link">
    Steps
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    Citation
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_lstm_neuralnetwork/" class="md-nav__link">
        Long Short Term Memory Neural Networks (LSTM)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_autoencoder/" class="md-nav__link">
        Autoencoders (AE)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_fc_overcomplete_ae/" class="md-nav__link">
        Fully-connected Overcomplete Autoencoder (AE)
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_4" type="checkbox" id="__nav_3_4" >
      
      <label class="md-nav__link" for="__nav_3_4">
        Improving Deep Learning with PyTorch
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Improving Deep Learning with PyTorch" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_4">
          <span class="md-nav__icon md-icon"></span>
          Improving Deep Learning with PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/derivative_gradient_jacobian/" class="md-nav__link">
        Derivative, Gradient and Jacobian
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/forwardpropagation_backpropagation_gradientdescent/" class="md-nav__link">
        Forward- and Backward-propagation and Gradient Descent (From Scratch FNN Regression)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/lr_scheduling/" class="md-nav__link">
        Learning Rate Scheduling
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/optimizers/" class="md-nav__link">
        Optimization Algorithms
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/weight_initialization_activation_functions/" class="md-nav__link">
        Weight Initialization and Activation Functions
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_5" type="checkbox" id="__nav_3_5" >
      
      <label class="md-nav__link" for="__nav_3_5">
        Deep Reinforcement Learning with PyTorch
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Deep Reinforcement Learning with PyTorch" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_5">
          <span class="md-nav__icon md-icon"></span>
          Deep Reinforcement Learning with PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../deep_reinforcement_learning_pytorch/supervised_to_rl/" class="md-nav__link">
        Supervised Learning to Reinforcement Learning (RL)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../deep_reinforcement_learning_pytorch/bellman_mdp/" class="md-nav__link">
        Markov Decision Processes (MDP) and Bellman Equations
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../deep_reinforcement_learning_pytorch/dynamic_programming_frozenlake/" class="md-nav__link">
        Dynamic Programming
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_6" type="checkbox" id="__nav_3_6" >
      
      <label class="md-nav__link" for="__nav_3_6">
        From Scratch Deep Learning with Python/PyTorch
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="From Scratch Deep Learning with Python/PyTorch" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_6">
          <span class="md-nav__icon md-icon"></span>
          From Scratch Deep Learning with Python/PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../fromscratch/fromscratch_logistic_regression/" class="md-nav__link">
        From Scratch Logistic Regression Classification
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_7" type="checkbox" id="__nav_3_7" >
      
      <label class="md-nav__link" for="__nav_3_7">
        Compute Optimization
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Compute Optimization" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_7">
          <span class="md-nav__icon md-icon"></span>
          Compute Optimization
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../production_pytorch/speed_optimization_basics_numba/" class="md-nav__link">
        Speed Optimization Basics Numba
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      <label class="md-nav__link" for="__nav_4">
        Machine Learning (CPU/GPU)
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Machine Learning (CPU/GPU)" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Machine Learning (CPU/GPU)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../machine_learning/intro/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

          
            
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" >
      
      <label class="md-nav__link" for="__nav_4_2">
        RAPIDS cuDF
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="RAPIDS cuDF" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          RAPIDS cuDF
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../machine_learning/gpu/rapids_cudf/" class="md-nav__link">
        GPU DataFrames
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../machine_learning/gpu/gpu_fractional_differencing/" class="md-nav__link">
        GPU/CPU Fractional Differencing
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      <label class="md-nav__link" for="__nav_5">
        Programming
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Programming" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Programming
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/intro/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/cpp/cpp/" class="md-nav__link">
        C++
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/bash/bash/" class="md-nav__link">
        Bash
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/python/python/" class="md-nav__link">
        Python
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/r/r/" class="md-nav__link">
        R
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/javascript/javascript/" class="md-nav__link">
        Javascript
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/electron/electron/" class="md-nav__link">
        Electron
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/sympy/calculus_sympy/" class="md-nav__link">
        Sympy
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/numpycupy/linalg_numpy_cupy/" class="md-nav__link">
        NumPy and CuPy
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      <label class="md-nav__link" for="__nav_6">
        Data Engineering
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Data Engineering" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Data Engineering
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_1" type="checkbox" id="__nav_6_1" >
      
      <label class="md-nav__link" for="__nav_6_1">
        Cassandra (NoSQL)
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Cassandra (NoSQL)" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_1">
          <span class="md-nav__icon md-icon"></span>
          Cassandra (NoSQL)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../data_engineering/nosql/cassandra/intro/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../data_engineering/nosql/cassandra/setting_up_cluster/" class="md-nav__link">
        Cassandra Cluster Setup
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" >
      
      <label class="md-nav__link" for="__nav_7">
        News
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="News" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          News
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/news/" class="md-nav__link">
        Welcome
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/dbs_gpu_rapids_nvidia_ensemble_frac_diff/" class="md-nav__link">
        Fractional Differencing with GPU (GFD), DBS and NVIDIA, September 2019
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/defence_and_science_technology_agency_dsta_nvidia_talk_2016_06/" class="md-nav__link">
        Deep Learning Introduction, Defence and Science Technology Agency (DSTA) and NVIDIA, June 2019
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/detect_waterbone_debris_ai_for_social_good_icml_2019_06/" class="md-nav__link">
        Oral Presentation for AI for Social Good Workshop ICML, June 2019
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/it_youth_leader_2019_03_11/" class="md-nav__link">
        IT Youth Leader of The Year 2019, March 2019
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/ammi_facebook_google_recap_2018_11_21/" class="md-nav__link">
        AMMI (AIMS) supported by Facebook and Google, November 2018
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/nanjing_next_nus_tsinghua_ai_finance_healthcare_2018_11_01/" class="md-nav__link">
        NExT++ AI in Healthcare and Finance, Nanjing, November 2018
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/facebook_pytorch_devcon_recap_2018_10_02/" class="md-nav__link">
        Recap of Facebook PyTorch Developer Conference, San Francisco, September 2018
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/facebook_pytorch_developer_conference_2018_09_05/" class="md-nav__link">
        Facebook PyTorch Developer Conference, San Francisco, September 2018
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/nvidia_nus_mit_datathon_2018_07_05/" class="md-nav__link">
        NUS-MIT-NUHS NVIDIA Image Recognition Workshop, Singapore, July 2018
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/deep_learning_wizard_1y_2018_06_01/" class="md-nav__link">
        Featured on PyTorch Website 2018
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/nvidia_self_driving_cars_talk_2017_06_21/" class="md-nav__link">
        NVIDIA Self Driving Cars & Healthcare Talk, Singapore, June 2017
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/deep_learning_wizard_nvidia_inception_2018_05_01/" class="md-nav__link">
        NVIDIA Inception Partner Status, Singapore, May 2017
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#about-recurrent-neural-network" class="md-nav__link">
    About Recurrent Neural Network
  </a>
  
    <nav class="md-nav" aria-label="About Recurrent Neural Network">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#feedforward-neural-networks-transition-to-1-layer-recurrent-neural-networks-rnn" class="md-nav__link">
    Feedforward Neural Networks Transition to 1 Layer Recurrent Neural Networks (RNN)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-layer-rnn-breakdown" class="md-nav__link">
    2 Layer RNN Breakdown
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-a-recurrent-neural-network-with-pytorch" class="md-nav__link">
    Building a Recurrent Neural Network with PyTorch
  </a>
  
    <nav class="md-nav" aria-label="Building a Recurrent Neural Network with PyTorch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-a-1-hidden-layer-relu" class="md-nav__link">
    Model A: 1 Hidden Layer (ReLU)
  </a>
  
    <nav class="md-nav" aria-label="Model A: 1 Hidden Layer (ReLU)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#steps" class="md-nav__link">
    Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1-loading-mnist-train-dataset" class="md-nav__link">
    Step 1: Loading MNIST Train Dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-make-dataset-iterable" class="md-nav__link">
    Step 2: Make Dataset Iterable
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-create-model-class" class="md-nav__link">
    Step 3: Create Model Class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-instantiate-model-class" class="md-nav__link">
    Step 4: Instantiate Model Class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-5-instantiate-loss-class" class="md-nav__link">
    Step 5: Instantiate Loss Class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-6-instantiate-optimizer-class" class="md-nav__link">
    Step 6: Instantiate Optimizer Class
  </a>
  
    <nav class="md-nav" aria-label="Step 6: Instantiate Optimizer Class">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters-in-depth" class="md-nav__link">
    Parameters In-Depth
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-7-train-model" class="md-nav__link">
    Step 7: Train Model
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-b-2-hidden-layer-relu" class="md-nav__link">
    Model B: 2 Hidden Layer (ReLU)
  </a>
  
    <nav class="md-nav" aria-label="Model B: 2 Hidden Layer (ReLU)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#steps_1" class="md-nav__link">
    Steps
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-c-2-hidden-layer" class="md-nav__link">
    Model C: 2 Hidden Layer
  </a>
  
    <nav class="md-nav" aria-label="Model C: 2 Hidden Layer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#steps_2" class="md-nav__link">
    Steps
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-of-results" class="md-nav__link">
    Summary of Results
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#general-deep-learning-notes" class="md-nav__link">
    General Deep Learning Notes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-building-a-recurrent-neural-network-with-pytorch-gpu" class="md-nav__link">
    3. Building a Recurrent Neural Network with PyTorch (GPU)
  </a>
  
    <nav class="md-nav" aria-label="3. Building a Recurrent Neural Network with PyTorch (GPU)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-c-2-hidden-layer-tanh" class="md-nav__link">
    Model C: 2 Hidden Layer (Tanh)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steps_3" class="md-nav__link">
    Steps
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    Citation
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/ritchieng/deep-learning-wizard/edit/master/docs/deep_learning/practical_pytorch/pytorch_recurrent_neuralnetwork.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <h1 id="recurrent-neural-network-with-pytorch">Recurrent Neural Network with PyTorch<a class="headerlink" href="#recurrent-neural-network-with-pytorch" title="Permanent link">&para;</a></h1>
<div class="admonition tip">
<p class="admonition-title">Run Jupyter Notebook</p>
<p>You can run the code for this section in this <a href="https://github.com/ritchieng/deep-learning-wizard/blob/master/docs/deep_learning/practical_pytorch/pytorch_recurrent_neuralnetwork.ipynb">jupyter notebook link</a>.</p>
</div>
<h2 id="about-recurrent-neural-network">About Recurrent Neural Network<a class="headerlink" href="#about-recurrent-neural-network" title="Permanent link">&para;</a></h2>
<h3 id="feedforward-neural-networks-transition-to-1-layer-recurrent-neural-networks-rnn">Feedforward Neural Networks Transition to 1 Layer Recurrent Neural Networks (RNN)<a class="headerlink" href="#feedforward-neural-networks-transition-to-1-layer-recurrent-neural-networks-rnn" title="Permanent link">&para;</a></h3>
<ul>
<li>RNN is essentially an FNN but with a hidden layer (non-linear output) that passes on information to the next FNN</li>
<li>Compared to an FNN, we've one additional set of weight and bias that allows information to flow from one FNN to another FNN sequentially that allows time-dependency.</li>
<li>The diagram below shows the only difference between an FNN and a RNN.
<img alt="" src="../images/rnn0-1.png" /></li>
</ul>
<h3 id="2-layer-rnn-breakdown">2 Layer RNN Breakdown<a class="headerlink" href="#2-layer-rnn-breakdown" title="Permanent link">&para;</a></h3>
<p><img alt="" src="../images/rnn0-2.png" /></p>
<h2 id="building-a-recurrent-neural-network-with-pytorch">Building a Recurrent Neural Network with PyTorch<a class="headerlink" href="#building-a-recurrent-neural-network-with-pytorch" title="Permanent link">&para;</a></h2>
<h3 id="model-a-1-hidden-layer-relu">Model A: 1 Hidden Layer (ReLU)<a class="headerlink" href="#model-a-1-hidden-layer-relu" title="Permanent link">&para;</a></h3>
<ul>
<li>Unroll 28 time steps<ul>
<li>Each step input size: 28 x 1</li>
<li>Total per unroll: 28 x 28<ul>
<li>Feedforward Neural Network input size: 28 x 28 </li>
</ul>
</li>
</ul>
</li>
<li>1 Hidden layer</li>
<li>ReLU Activation Function</li>
</ul>
<p><img alt="" src="../images/rnn2n.png" /></p>
<h4 id="steps">Steps<a class="headerlink" href="#steps" title="Permanent link">&para;</a></h4>
<ul>
<li>Step 1: Load Dataset</li>
<li>Step 2: Make Dataset Iterable</li>
<li>Step 3: Create Model Class</li>
<li>Step 4: Instantiate Model Class</li>
<li>Step 5: Instantiate Loss Class</li>
<li>Step 6: Instantiate Optimizer Class</li>
<li>Step 7: Train Model</li>
</ul>
<h4 id="step-1-loading-mnist-train-dataset">Step 1: Loading MNIST Train Dataset<a class="headerlink" href="#step-1-loading-mnist-train-dataset" title="Permanent link">&para;</a></h4>
<p><strong>Images from 1 to 9</strong></p>
<div class="admonition note">
<p class="admonition-title">Looking into the MNIST Dataset</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dsets</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>
</code></pre></div>
<p>We would have 60k training images of size 28 x 28 pixels.</p>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">train_data</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">train_labels</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</code></pre></div>
<p>Here we would have 10k testing images of the same size, 28 x 28 pixels.</p>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">test_data</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">test_labels</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>

<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">60000</span><span class="p">])</span>

<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>

<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10000</span><span class="p">])</span>
</code></pre></div>
<h4 id="step-2-make-dataset-iterable">Step 2: Make Dataset Iterable<a class="headerlink" href="#step-2-make-dataset-iterable" title="Permanent link">&para;</a></h4>
<div class="admonition note">
<p class="admonition-title">Creating iterable objects to loop through subsequently</p>
<div class="highlight"><pre><span></span><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="n">n_iters</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
</div>
<h4 id="step-3-create-model-class">Step 3: Create Model Class<a class="headerlink" href="#step-3-create-model-class" title="Permanent link">&para;</a></h4>
<div class="admonition note">
<p class="admonition-title">1 Layer RNN</p>
<p><img alt="" src="../images/rnn2n.png" /></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">RNNModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RNNModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Hidden dimensions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>

        <span class="c1"># Number of hidden layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_dim</span> <span class="o">=</span> <span class="n">layer_dim</span>

        <span class="c1"># Building your RNN</span>
        <span class="c1"># batch_first=True causes input/output tensors to be of shape</span>
        <span class="c1"># (batch_dim, seq_dim, input_dim)</span>
        <span class="c1"># batch_dim = number of samples per batch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>

        <span class="c1"># Readout layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Initialize hidden state with zeros</span>
        <span class="c1"># (layer_dim, batch_size, hidden_dim)</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_dim</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

        <span class="c1"># We need to detach the hidden state to prevent exploding/vanishing gradients</span>
        <span class="c1"># This is part of truncated backpropagation through time (BPTT)</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

        <span class="c1"># Index hidden state of last time step</span>
        <span class="c1"># out.size() --&gt; 100, 28, 10</span>
        <span class="c1"># out[:, -1, :] --&gt; 100, 10 --&gt; just want last time step hidden states! </span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span> 
        <span class="c1"># out.size() --&gt; 100, 10</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div>
</div>
<h4 id="step-4-instantiate-model-class">Step 4: Instantiate Model Class<a class="headerlink" href="#step-4-instantiate-model-class" title="Permanent link">&para;</a></h4>
<ul>
<li>28 time steps<ul>
<li>Each time step: input dimension = 28</li>
</ul>
</li>
<li>1 hidden layer</li>
<li>MNIST 1-9 digits <span class="arithmatex">\(\rightarrow\)</span> output dimension = 10</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Instantiate model class and assign to an object</p>
<div class="highlight"><pre><span></span><code><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">layer_dim</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
</code></pre></div>
</div>
<h4 id="step-5-instantiate-loss-class">Step 5: Instantiate Loss Class<a class="headerlink" href="#step-5-instantiate-loss-class" title="Permanent link">&para;</a></h4>
<ul>
<li>Recurrent Neural Network: <strong>Cross Entropy Loss</strong><ul>
<li><em>Convolutional Neural Network</em>: <strong>Cross Entropy Loss</strong></li>
<li><em>Feedforward Neural Network</em>: <strong>Cross Entropy Loss</strong></li>
<li><em>Logistic Regression</em>: <strong>Cross Entropy Loss</strong></li>
<li><em>Linear Regression</em>: <strong>MSE</strong></li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Cross Entropy Loss for Classification Task</p>
<div class="highlight"><pre><span></span><code><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</code></pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Cross Entropy vs MSE</p>
<p>Take note that there are cases where RNN, CNN and FNN use MSE as a loss function.</p>
<p>We use cross entropy for classification tasks (predicting 0-9 digits in MNIST for example).</p>
<p>And we use MSE for regression tasks (predicting temperatures in every December in San Francisco for example).</p>
</div>
<h4 id="step-6-instantiate-optimizer-class">Step 6: Instantiate Optimizer Class<a class="headerlink" href="#step-6-instantiate-optimizer-class" title="Permanent link">&para;</a></h4>
<ul>
<li>Simplified equation<ul>
<li><span class="arithmatex">\(\theta = \theta - \eta \cdot \nabla_\theta\)</span><ul>
<li><span class="arithmatex">\(\theta\)</span>: parameters (our tensors with gradient accumulation abilities)</li>
<li><span class="arithmatex">\(\eta\)</span>: learning rate (how fast we want to learn)</li>
<li><span class="arithmatex">\(\nabla_\theta\)</span>: gradients of loss with respect to the model's parameters</li>
</ul>
</li>
</ul>
</li>
<li>Even simplier equation<ul>
<li><code>parameters = parameters - learning_rate * parameters_gradients</code></li>
<li><strong>At every iteration, we update our model's parameters</strong></li>
</ul>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>  
</code></pre></div>
<h6 id="parameters-in-depth">Parameters In-Depth<a class="headerlink" href="#parameters-in-depth" title="Permanent link">&para;</a></h6>
<ul>
<li>Input to Hidden Layer Affine Function<ul>
<li>A1, B1</li>
</ul>
</li>
<li>Hidden Layer to Output Affine Function<ul>
<li>A2, B2</li>
</ul>
</li>
<li>Hidden Layer to Hidden Layer Affine Function<ul>
<li>A3, B3</li>
</ul>
</li>
</ul>
<p><img alt="" src="./images/rnn4n.pn" /></p>
<div class="admonition note">
<p class="admonition-title">Total groups of parameters</p>
<p>We should have 6 groups as shown above.</p>
<div class="highlight"><pre><span></span><code><span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="mi">6</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Input to Hidden Weight</p>
<p>Remember we defined our hidden layer to have a size of 100. Because our input is a size of 28 at each time step, this gives rise to a weight matrix of 100 x 28.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Input --&gt; Hidden (A1)</span>
<span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Input to Hidden Bias</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Input --&gt; Hidden BIAS (B1)</span>
<span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Hidden to Hidden</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Hidden --&gt; Hidden (A3)</span>
<span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Hidden to Hidden Bias</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Hidden --&gt; Hidden BIAS(B3)</span>
<span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Hidden to Output</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Hidden --&gt; Output (A2)</span>
<span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Hidden to Output Bias</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Hidden --&gt; Output BIAS (B2)</span>
<span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span>
</code></pre></div>
<h4 id="step-7-train-model">Step 7: Train Model<a class="headerlink" href="#step-7-train-model" title="Permanent link">&para;</a></h4>
<ul>
<li>Process <ol>
<li><strong>Convert inputs/labels to tensors with gradient accumulation abilities</strong><ul>
<li>RNN Input: (1, 28)</li>
<li>CNN Input: (1, 28, 28) </li>
<li>FNN Input: (1, 28*28)</li>
</ul>
</li>
<li>Clear gradient buffets</li>
<li>Get output given inputs </li>
<li>Get loss</li>
<li>Get gradients w.r.t. parameters</li>
<li>Update parameters using gradients<ul>
<li><code>parameters = parameters - learning_rate * parameters_gradients</code></li>
</ul>
</li>
<li>REPEAT</li>
</ol>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Same 7 step process for training models</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Number of steps to unroll</span>
<span class="n">seq_dim</span> <span class="o">=</span> <span class="mi">28</span>  

<span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="c1"># Load images as tensors with gradient accumulation abilities</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

        <span class="c1"># Clear gradients w.r.t. parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass to get output/logits</span>
        <span class="c1"># outputs.size() --&gt; 100, 10</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Getting gradients w.r.t. parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updating parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="c1"># Calculate Accuracy         </span>
            <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Iterate through test dataset</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="c1"># Load images to a Torch tensors with gradient accumulation abilities</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>

                <span class="c1"># Forward pass only to get logits/output</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

                <span class="c1"># Get predictions from the maximum value</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Total number of labels</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># Total correct predictions</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

            <span class="c1"># Print Loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="s1">. Loss: </span><span class="si">{}</span><span class="s1">. Accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">Iteration</span><span class="p">:</span> <span class="mf">500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.301494836807251</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">12</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.2986037731170654</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">14</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.278566598892212</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">18</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.169614315032959</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">21</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.1662731170654297</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">51</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">3000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.9290509223937988</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">71</span>
</code></pre></div>
<h3 id="model-b-2-hidden-layer-relu">Model B: 2 Hidden Layer (ReLU)<a class="headerlink" href="#model-b-2-hidden-layer-relu" title="Permanent link">&para;</a></h3>
<ul>
<li>Unroll 28 time steps<ul>
<li>Each step input size: 28 x 1</li>
<li>Total per unroll: 28 x 28<ul>
<li>Feedforward Neural Network inpt size: 28 x 28 </li>
</ul>
</li>
</ul>
</li>
<li><strong>2 Hidden layer</strong></li>
<li>ReLU Activation Function</li>
</ul>
<p><img alt="" src="../images/rnn5nr.png" /></p>
<h4 id="steps_1">Steps<a class="headerlink" href="#steps_1" title="Permanent link">&para;</a></h4>
<ul>
<li>Step 1: Load Dataset</li>
<li>Step 2: Make Dataset Iterable</li>
<li>Step 3: Create Model Class</li>
<li><strong>Step 4: Instantiate Model Class</strong></li>
<li>Step 5: Instantiate Loss Class</li>
<li>Step 6: Instantiate Optimizer Class</li>
<li>Step 7: Train Model</li>
</ul>
<div class="admonition note">
<p class="admonition-title">2 Hidden Layer + ReLU</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dsets</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 1: LOADING DATASET</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 2: MAKING DATASET ITERABLE</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="n">n_iters</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 3: CREATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="k">class</span> <span class="nc">RNNModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RNNModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Hidden dimensions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>

        <span class="c1"># Number of hidden layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_dim</span> <span class="o">=</span> <span class="n">layer_dim</span>

        <span class="c1"># Building your RNN</span>
        <span class="c1"># batch_first=True causes input/output tensors to be of shape</span>
        <span class="c1"># (batch_dim, seq_dim, feature_dim)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>

        <span class="c1"># Readout layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Initialize hidden state with zeros</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_dim</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

        <span class="c1"># We need to detach the hidden state to prevent exploding/vanishing gradients</span>
        <span class="c1"># This is part of truncated backpropagation through time (BPTT)</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

        <span class="c1"># Index hidden state of last time step</span>
        <span class="c1"># out.size() --&gt; 100, 28, 100</span>
        <span class="c1"># out[:, -1, :] --&gt; 100, 100 --&gt; just want last time step hidden states! </span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span> 
        <span class="c1"># out.size() --&gt; 100, 10</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 4: INSTANTIATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">layer_dim</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

<span class="c1"># JUST PRINTING MODEL &amp; PARAMETERS </span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))):</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 5: INSTANTIATE LOSS CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>  

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 7: TRAIN THE MODEL</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="c1"># Number of steps to unroll</span>
<span class="n">seq_dim</span> <span class="o">=</span> <span class="mi">28</span>  

<span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="c1"># Load images as tensors with gradient accumulation abilities</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

        <span class="c1"># Clear gradients w.r.t. parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass to get output/logits</span>
        <span class="c1"># outputs.size() --&gt; 100, 10</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Getting gradients w.r.t. parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updating parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="c1"># Calculate Accuracy         </span>
            <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Iterate through test dataset</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="c1"># Resize images</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>

                <span class="c1"># Forward pass only to get logits/output</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

                <span class="c1"># Get predictions from the maximum value</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Total number of labels</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># Total correct predictions</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

            <span class="c1"># Print Loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="s1">. Loss: </span><span class="si">{}</span><span class="s1">. Accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">RNNModel</span><span class="p">(</span>
  <span class="p">(</span><span class="n">rnn</span><span class="p">):</span> <span class="n">RNN</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="p">(</span><span class="n">fc</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>

<span class="mi">10</span>

<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span>

<span class="n">Iteration</span><span class="p">:</span> <span class="mf">500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.3019518852233887</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">11</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.299217700958252</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">11</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.279090166091919</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">14</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.126953125</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">25</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.356347680091858</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">57</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">3000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.7377720475196838</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">69</span>
</code></pre></div>
<ul>
<li><strong>10 sets of parameters</strong></li>
<li>First hidden Layer<ul>
<li><span class="arithmatex">\(A_1 = [100, 28]\)</span></li>
<li><span class="arithmatex">\(A_3 = [100, 100]\)</span></li>
<li><span class="arithmatex">\(B_1 = [100]\)</span></li>
<li><span class="arithmatex">\(B_3 = [100]\)</span></li>
</ul>
</li>
<li>Second hidden layer<ul>
<li><span class="arithmatex">\(A_2 = [100, 100]\)</span></li>
<li><span class="arithmatex">\(A_5 = [100, 100]\)</span></li>
<li><span class="arithmatex">\(B_2 = [100]\)</span></li>
<li><span class="arithmatex">\(B_5 = [100]\)</span></li>
</ul>
</li>
<li>Readout layer<ul>
<li><span class="arithmatex">\(A_4 = [10, 100]\)</span></li>
<li><span class="arithmatex">\(B_4 = [10]\)</span></li>
</ul>
</li>
</ul>
<p><img alt="" src="../images/rnn6.png" /></p>
<h3 id="model-c-2-hidden-layer">Model C: 2 Hidden Layer<a class="headerlink" href="#model-c-2-hidden-layer" title="Permanent link">&para;</a></h3>
<ul>
<li>Unroll 28 time steps<ul>
<li>Each step input size: 28 x 1</li>
<li>Total per unroll: 28 x 28<ul>
<li>Feedforward Neural Network inpt size: 28 x 28 </li>
</ul>
</li>
</ul>
</li>
<li>2 Hidden layer</li>
<li><strong>Tanh</strong> Activation Function</li>
</ul>
<p><img alt="" src="../images/rnn5nr.png" /></p>
<h4 id="steps_2">Steps<a class="headerlink" href="#steps_2" title="Permanent link">&para;</a></h4>
<ul>
<li>Step 1: Load Dataset</li>
<li>Step 2: Make Dataset Iterable</li>
<li>Step 3: Create Model Class</li>
<li><strong>Step 4: Instantiate Model Class</strong></li>
<li>Step 5: Instantiate Loss Class</li>
<li>Step 6: Instantiate Optimizer Class</li>
<li>Step 7: Train Model</li>
</ul>
<p>!!! "2 Hidden + ReLU"
    <div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dsets</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 1: LOADING DATASET</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 2: MAKING DATASET ITERABLE</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="n">n_iters</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 3: CREATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="k">class</span> <span class="nc">RNNModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RNNModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Hidden dimensions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>

        <span class="c1"># Number of hidden layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_dim</span> <span class="o">=</span> <span class="n">layer_dim</span>

        <span class="c1"># Building your RNN</span>
        <span class="c1"># batch_first=True causes input/output tensors to be of shape</span>
        <span class="c1"># (batch_dim, seq_dim, feature_dim)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">)</span>

        <span class="c1"># Readout layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Initialize hidden state with zeros</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_dim</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

        <span class="c1"># One time step</span>
        <span class="c1"># We need to detach the hidden state to prevent exploding/vanishing gradients</span>
        <span class="c1"># This is part of truncated backpropagation through time (BPTT)</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

        <span class="c1"># Index hidden state of last time step</span>
        <span class="c1"># out.size() --&gt; 100, 28, 100</span>
        <span class="c1"># out[:, -1, :] --&gt; 100, 100 --&gt; just want last time step hidden states! </span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span> 
        <span class="c1"># out.size() --&gt; 100, 10</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 4: INSTANTIATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">layer_dim</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

<span class="c1"># JUST PRINTING MODEL &amp; PARAMETERS </span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))):</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 5: INSTANTIATE LOSS CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>  

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 7: TRAIN THE MODEL</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="c1"># Number of steps to unroll</span>
<span class="n">seq_dim</span> <span class="o">=</span> <span class="mi">28</span>  

<span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="c1"># Load images as tensors with gradient accumulation abilities</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

        <span class="c1"># Clear gradients w.r.t. parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass to get output/logits</span>
        <span class="c1"># outputs.size() --&gt; 100, 10</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Getting gradients w.r.t. parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updating parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate Accuracy         </span>
            <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Iterate through test dataset</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="c1"># Resize images</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>

                <span class="c1"># Forward pass only to get logits/output</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

                <span class="c1"># Get predictions from the maximum value</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Total number of labels</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># Total correct predictions</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

            <span class="c1"># Print Loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="s1">. Loss: </span><span class="si">{}</span><span class="s1">. Accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
</code></pre></div></p>
<div class="highlight"><pre><span></span><code><span class="n">RNNModel</span><span class="p">(</span>
  <span class="p">(</span><span class="n">rnn</span><span class="p">):</span> <span class="n">RNN</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="p">(</span><span class="n">fc</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>

<span class="mi">10</span>

<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5943437218666077</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">77</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.22048641741275787</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">91</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.18479223549365997</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">94</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2723771929740906</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">91</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.18817797303199768</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">92</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">3000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1685929149389267</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">92</span>
</code></pre></div>
<h2 id="summary-of-results">Summary of Results<a class="headerlink" href="#summary-of-results" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Model A</th>
<th>Model B</th>
<th>Model C</th>
</tr>
</thead>
<tbody>
<tr>
<td>ReLU</td>
<td>ReLU</td>
<td>Tanh</td>
</tr>
<tr>
<td>1 Hidden Layer</td>
<td>2 Hidden Layers</td>
<td>2 Hidden Layers</td>
</tr>
<tr>
<td>100 Hidden Units</td>
<td>100 Hidden Units</td>
<td>100 Hidden Units</td>
</tr>
<tr>
<td>92.48%</td>
<td>95.09%</td>
<td>95.54%</td>
</tr>
</tbody>
</table>
<h2 id="general-deep-learning-notes">General Deep Learning Notes<a class="headerlink" href="#general-deep-learning-notes" title="Permanent link">&para;</a></h2>
<ul>
<li>2 ways to expand a recurrent neural network<ul>
<li>More non-linear activation units (neurons)</li>
<li>More hidden layers</li>
</ul>
</li>
<li>Cons<ul>
<li>Need a larger dataset<ul>
<li>Curse of dimensionality</li>
</ul>
</li>
<li>Does not necessarily mean higher accuracy</li>
</ul>
</li>
</ul>
<h2 id="3-building-a-recurrent-neural-network-with-pytorch-gpu">3. Building a Recurrent Neural Network with PyTorch (GPU)<a class="headerlink" href="#3-building-a-recurrent-neural-network-with-pytorch-gpu" title="Permanent link">&para;</a></h2>
<h3 id="model-c-2-hidden-layer-tanh">Model C: 2 Hidden Layer (Tanh)<a class="headerlink" href="#model-c-2-hidden-layer-tanh" title="Permanent link">&para;</a></h3>
<p><img alt="" src="../images/rnn5nr.png" /></p>
<p>GPU: 2 things must be on GPU
- <code>model</code>
- <code>tensors</code></p>
<h3 id="steps_3">Steps<a class="headerlink" href="#steps_3" title="Permanent link">&para;</a></h3>
<ul>
<li>Step 1: Load Dataset</li>
<li>Step 2: Make Dataset Iterable</li>
<li><strong>Step 3: Create Model Class</strong></li>
<li><strong>Step 4: Instantiate Model Class</strong></li>
<li>Step 5: Instantiate Loss Class</li>
<li>Step 6: Instantiate Optimizer Class</li>
<li><strong>Step 7: Train Model</strong></li>
</ul>
<div class="admonition note">
<p class="admonition-title">2 Layer RNN + Tanh</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dsets</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 1: LOADING DATASET</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 2: MAKING DATASET ITERABLE</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="n">n_iters</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 3: CREATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="k">class</span> <span class="nc">RNNModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RNNModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Hidden dimensions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>

        <span class="c1"># Number of hidden layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_dim</span> <span class="o">=</span> <span class="n">layer_dim</span>

        <span class="c1"># Building your RNN</span>
        <span class="c1"># batch_first=True causes input/output tensors to be of shape</span>
        <span class="c1"># (batch_dim, seq_dim, feature_dim)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">)</span>

        <span class="c1"># Readout layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Initialize hidden state with zeros</span>
        <span class="c1">#######################</span>
        <span class="c1">#  USE GPU FOR MODEL  #</span>
        <span class="c1">#######################</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_dim</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># One time step</span>
        <span class="c1"># We need to detach the hidden state to prevent exploding/vanishing gradients</span>
        <span class="c1"># This is part of truncated backpropagation through time (BPTT)</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

        <span class="c1"># Index hidden state of last time step</span>
        <span class="c1"># out.size() --&gt; 100, 28, 100</span>
        <span class="c1"># out[:, -1, :] --&gt; 100, 100 --&gt; just want last time step hidden states! </span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span> 
        <span class="c1"># out.size() --&gt; 100, 10</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 4: INSTANTIATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">layer_dim</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">layer_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

<span class="c1">#######################</span>
<span class="c1">#  USE GPU FOR MODEL  #</span>
<span class="c1">#######################</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>


<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 5: INSTANTIATE LOSS CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>  

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 7: TRAIN THE MODEL</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="c1"># Number of steps to unroll</span>
<span class="n">seq_dim</span> <span class="o">=</span> <span class="mi">28</span>  

<span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="c1"># Load images as tensors with gradient accumulation abilities</span>
        <span class="c1">#######################</span>
        <span class="c1">#  USE GPU FOR MODEL  #</span>
        <span class="c1">#######################</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Clear gradients w.r.t. parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass to get output/logits</span>
        <span class="c1"># outputs.size() --&gt; 100, 10</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Getting gradients w.r.t. parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updating parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate Accuracy         </span>
            <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Iterate through test dataset</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="c1">#######################</span>
                <span class="c1">#  USE GPU FOR MODEL  #</span>
                <span class="c1">#######################</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># Forward pass only to get logits/output</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

                <span class="c1"># Get predictions from the maximum value</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Total number of labels</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># Total correct predictions</span>
                <span class="c1">#######################</span>
                <span class="c1">#  USE GPU FOR MODEL  #</span>
                <span class="c1">#######################</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                    <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="o">==</span> <span class="n">labels</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

            <span class="c1"># Print Loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="s1">. Loss: </span><span class="si">{}</span><span class="s1">. Accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">Iteration</span><span class="p">:</span> <span class="mf">500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5983774662017822</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">81</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2960105836391449</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">86</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.19428101181983948</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">93</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.11918395012617111</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">95</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.11246936023235321</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">95</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">3000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.15849310159683228</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">95</span>
</code></pre></div>
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h2>
<p>We've learnt to...</p>
<div class="admonition success">
<p class="admonition-title">Success</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Feedforward Neural Networks</strong> Transition to Recurrent Neural Networks</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>RNN Models</strong> in PyTorch<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Model A: 1 Hidden Layer RNN (ReLU)</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Model B: 2 Hidden Layer RNN (ReLU)</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Model C: 2 Hidden Layer RNN (Tanh)</li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Models Variation in <strong>Code</strong><ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Modifying only step 4</li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Ways to Expand Model’s <strong>Capacity</strong><ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> More non-linear activation units (<strong>neurons</strong>)</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> More hidden <strong>layers</strong></li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Cons</strong> of Expanding Capacity<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Need more <strong>data</strong></li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Does not necessarily mean higher <strong>accuracy</strong></li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>GPU</strong> Code<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 2 things on GPU<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>model</strong></li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>tensors with gradient accumulation abilities</strong></li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Modifying only <strong>Step 3, 4 and 7</strong></li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>7 Step</strong> Model Building Recap<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 1: Load Dataset</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 2: Make Dataset Iterable</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Step 3: Create Model Class</strong></li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Step 4: Instantiate Model Class</strong></li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 5: Instantiate Loss Class</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 6: Instantiate Optimizer Class</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Step 7: Train Model</strong></li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Step 7: Train Model</strong></li>
</ul>
</li>
</ul>
</div>
<h2 id="citation">Citation<a class="headerlink" href="#citation" title="Permanent link">&para;</a></h2>
<p>If you have found these useful in your research, presentations, school work, projects or workshops, feel free to cite using this DOI.</p>
<p><a href="https://zenodo.org/badge/latestdoi/139945544"><img alt="DOI" src="https://zenodo.org/badge/139945544.svg" /></a></p>
                
              
              
                


  <h2 id="__comments">Comments</h2>
  <div id="disqus_thread"></div>
  <script>var disqus_config=function(){this.page.url="https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_recurrent_neuralnetwork/",this.page.identifier="deep_learning/practical_pytorch/pytorch_recurrent_neuralnetwork/"};window.addEventListener("load",function(){var e=document,i=e.createElement("script");i.src="//deep-learning-wizard.disqus.com/embed.js",i.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(i)})</script>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Back to top
          </a>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../pytorch_convolutional_neuralnetwork/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Convolutional Neural Networks (CNN)" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Convolutional Neural Networks (CNN)
            </div>
          </div>
        </a>
      
      
        
        <a href="../pytorch_lstm_neuralnetwork/" class="md-footer__link md-footer__link--next" aria-label="Next: Long Short Term Memory Neural Networks (LSTM)" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Long Short Term Memory Neural Networks (LSTM)
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2023 Deep Learning Wizard by Ritchie Ng
          </div>
        
        
      </div>
      
  <div class="md-footer-social">
    
      
      
        
        
      
      <a href="https://www.youtube.com/channel/UCJz2MIjiCosOQCwhnsYxeEw" target="_blank" rel="noopener" title="www.youtube.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg>
      </a>
    
      
      
        
        
      
      <a href="https://twitter.com/deeplearningwiz" target="_blank" rel="noopener" title="twitter.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
      </a>
    
      
      
        
        
      
      <a href="https://www.facebook.com/DeepLearningWizard/" target="_blank" rel="noopener" title="www.facebook.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg>
      </a>
    
      
      
        
        
      
      <a href="https://www.linkedin.com/company/deeplearningwizard/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
      </a>
    
      
      
        
        
      
      <a href="https://github.com/ritchieng" target="_blank" rel="noopener" title="github.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
      </a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.annotate", "content.tabs.link", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../../assets/javascripts/workers/search.709b4209.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.56838a2c.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>