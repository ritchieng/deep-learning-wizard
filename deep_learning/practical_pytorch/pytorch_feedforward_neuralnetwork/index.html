
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="We try to make learning deep learning, deep bayesian learning, and deep reinforcement learning math and code easier. Used by thousands.">
      
      
      
        <meta name="author" content="Ritchie Ng">
      
      
        <link rel="canonical" href="https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork/">
      
      <link rel="icon" href="../../../docs/assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-7.2.4">
    
    
      
        <title>Feedforward Neural Networks (FNN) - Deep Learning Wizard</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.f7f47774.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.3f5d1f46.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
    
      

  


  

  


  <script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-122083328-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){var e;this.value&&(e=document.location.pathname,ga("send","pageview",e+"?q="+this.value))}),"undefined"!=typeof location$&&location$.subscribe(function(e){ga("send","pageview",e.pathname)})})</script>
  <script async src="https://www.google-analytics.com/analytics.js"></script>


    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <script>function __prefix(e){return new URL("../../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
      <script>var palette=__get("__palette");if(null!==palette&&"object"==typeof palette.color)for(var key in palette.color)document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#feedforward-neural-network-with-pytorch" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Deep Learning Wizard" class="md-header__button md-logo" aria-label="Deep Learning Wizard" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M396.8 352h22.4c6.4 0 12.8-6.4 12.8-12.8V108.8c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v230.4c0 6.4 6.4 12.8 12.8 12.8zm-192 0h22.4c6.4 0 12.8-6.4 12.8-12.8V140.8c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v198.4c0 6.4 6.4 12.8 12.8 12.8zm96 0h22.4c6.4 0 12.8-6.4 12.8-12.8V204.8c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v134.4c0 6.4 6.4 12.8 12.8 12.8zM496 400H48V80c0-8.84-7.16-16-16-16H16C7.16 64 0 71.16 0 80v336c0 17.67 14.33 32 32 32h464c8.84 0 16-7.16 16-16v-16c0-8.84-7.16-16-16-16zm-387.2-48h22.4c6.4 0 12.8-6.4 12.8-12.8v-70.4c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v70.4c0 6.4 6.4 12.8 12.8 12.8z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Deep Learning Wizard
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Feedforward Neural Networks (FNN)
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M7 10a2 2 0 0 1 2 2 2 2 0 0 1-2 2 2 2 0 0 1-2-2 2 2 0 0 1 2-2m10-3a5 5 0 0 1 5 5 5 5 0 0 1-5 5H7a5 5 0 0 1-5-5 5 5 0 0 1 5-5h10M7 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3h10a3 3 0 0 0 3-3 3 3 0 0 0-3-3H7z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3z"/></svg>
            </label>
          
        
      </form>
    
    
    
    
      <div class="md-header__source">
        
<a href="https://github.com/ritchieng/deep-learning-wizard" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ritchieng/deep-learning-wizard
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../.." class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../home/" class="md-tabs__link">
        About
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../intro/" class="md-tabs__link md-tabs__link--active">
        Deep Learning (CPU/GPU)
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../machine_learning/intro/" class="md-tabs__link">
        Machine Learning (CPU/GPU)
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../programming/intro/" class="md-tabs__link">
        Programming
      </a>
    </li>
  

      
        
  
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../data_engineering/nosql/cassandra/intro/" class="md-tabs__link">
        Data Engineering
      </a>
    </li>
  

  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../news/news/" class="md-tabs__link">
        News
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Deep Learning Wizard" class="md-nav__button md-logo" aria-label="Deep Learning Wizard" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M396.8 352h22.4c6.4 0 12.8-6.4 12.8-12.8V108.8c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v230.4c0 6.4 6.4 12.8 12.8 12.8zm-192 0h22.4c6.4 0 12.8-6.4 12.8-12.8V140.8c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v198.4c0 6.4 6.4 12.8 12.8 12.8zm96 0h22.4c6.4 0 12.8-6.4 12.8-12.8V204.8c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v134.4c0 6.4 6.4 12.8 12.8 12.8zM496 400H48V80c0-8.84-7.16-16-16-16H16C7.16 64 0 71.16 0 80v336c0 17.67 14.33 32 32 32h464c8.84 0 16-7.16 16-16v-16c0-8.84-7.16-16-16-16zm-387.2-48h22.4c6.4 0 12.8-6.4 12.8-12.8v-70.4c0-6.4-6.4-12.8-12.8-12.8h-22.4c-6.4 0-12.8 6.4-12.8 12.8v70.4c0 6.4 6.4 12.8 12.8 12.8z"/></svg>

    </a>
    Deep Learning Wizard
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/ritchieng/deep-learning-wizard" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ritchieng/deep-learning-wizard
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      <label class="md-nav__link" for="__nav_2">
        About
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="About" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          About
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../home/" class="md-nav__link">
        Intro
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../about/" class="md-nav__link">
        About Us
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../review/" class="md-nav__link">
        Reviews
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../consultancy/" class="md-nav__link">
        Consultancy
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      <label class="md-nav__link" for="__nav_3">
        Deep Learning (CPU/GPU)
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Deep Learning (CPU/GPU)" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Deep Learning (CPU/GPU)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../intro/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../course_progression/" class="md-nav__link">
        Course Progression
      </a>
    </li>
  

          
            
  
  
    
  
  
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_3" type="checkbox" id="__nav_3_3" checked>
      
      <label class="md-nav__link" for="__nav_3_3">
        Practical Deep Learning with PyTorch
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Practical Deep Learning with PyTorch" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_3">
          <span class="md-nav__icon md-icon"></span>
          Practical Deep Learning with PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_matrices/" class="md-nav__link">
        Matrices
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_gradients/" class="md-nav__link">
        Gradients
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_linear_regression/" class="md-nav__link">
        Linear Regression
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_logistic_regression/" class="md-nav__link">
        Logistic Regression
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Feedforward Neural Networks (FNN)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Feedforward Neural Networks (FNN)
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#about-feedforward-neural-network" class="md-nav__link">
    About Feedforward Neural Network
  </a>
  
    <nav class="md-nav" aria-label="About Feedforward Neural Network">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#logistic-regression-transition-to-neural-networks" class="md-nav__link">
    Logistic Regression Transition to Neural Networks
  </a>
  
    <nav class="md-nav" aria-label="Logistic Regression Transition to Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#logistic-regression-review" class="md-nav__link">
    Logistic Regression Review
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic-regression-problems" class="md-nav__link">
    Logistic Regression Problems
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#introducing-a-non-linear-function" class="md-nav__link">
    Introducing a Non-linear Function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#non-linear-function-in-depth" class="md-nav__link">
    Non-linear Function In-Depth
  </a>
  
    <nav class="md-nav" aria-label="Non-linear Function In-Depth">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sigmoid-logistic" class="md-nav__link">
    Sigmoid (Logistic)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tanh" class="md-nav__link">
    Tanh
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relus" class="md-nav__link">
    ReLUs
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-a-feedforward-neural-network-with-pytorch" class="md-nav__link">
    Building a Feedforward Neural Network with PyTorch
  </a>
  
    <nav class="md-nav" aria-label="Building a Feedforward Neural Network with PyTorch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-a-1-hidden-layer-feedforward-neural-network-sigmoid-activation" class="md-nav__link">
    Model A: 1 Hidden Layer Feedforward Neural Network (Sigmoid Activation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steps" class="md-nav__link">
    Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1-loading-mnist-train-dataset" class="md-nav__link">
    Step 1: Loading MNIST Train Dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-make-dataset-iterable" class="md-nav__link">
    Step 2: Make Dataset Iterable
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-create-model-class" class="md-nav__link">
    Step 3: Create Model Class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-instantiate-model-class" class="md-nav__link">
    Step 4: Instantiate Model Class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-5-instantiate-loss-class" class="md-nav__link">
    Step 5: Instantiate Loss Class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-6-instantiate-optimizer-class" class="md-nav__link">
    Step 6: Instantiate Optimizer Class
  </a>
  
    <nav class="md-nav" aria-label="Step 6: Instantiate Optimizer Class">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters-in-depth" class="md-nav__link">
    Parameters In-Depth
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-7-train-model" class="md-nav__link">
    Step 7: Train Model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-b-1-hidden-layer-feedforward-neural-network-tanh-activation" class="md-nav__link">
    Model B: 1 Hidden Layer Feedforward Neural Network (Tanh Activation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steps_1" class="md-nav__link">
    Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-c-1-hidden-layer-feedforward-neural-network-relu-activation" class="md-nav__link">
    Model C: 1 Hidden Layer Feedforward Neural Network (ReLU Activation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steps_2" class="md-nav__link">
    Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-d-2-hidden-layer-feedforward-neural-network-relu-activation" class="md-nav__link">
    Model D: 2 Hidden Layer Feedforward Neural Network (ReLU Activation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steps_3" class="md-nav__link">
    Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-e-3-hidden-layer-feedforward-neural-network-relu-activation" class="md-nav__link">
    Model E: 3 Hidden Layer Feedforward Neural Network (ReLU Activation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steps_4" class="md-nav__link">
    Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#general-comments-on-fnns" class="md-nav__link">
    General Comments on FNNs
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-building-a-feedforward-neural-network-with-pytorch-gpu" class="md-nav__link">
    3. Building a Feedforward Neural Network with PyTorch (GPU)
  </a>
  
    <nav class="md-nav" aria-label="3. Building a Feedforward Neural Network with PyTorch (GPU)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#steps_5" class="md-nav__link">
    Steps
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    Citation
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_convolutional_neuralnetwork/" class="md-nav__link">
        Convolutional Neural Networks (CNN)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_recurrent_neuralnetwork/" class="md-nav__link">
        Recurrent Neural Networks (RNN)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_lstm_neuralnetwork/" class="md-nav__link">
        Long Short Term Memory Neural Networks (LSTM)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_autoencoder/" class="md-nav__link">
        Autoencoders (AE)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_fc_overcomplete_ae/" class="md-nav__link">
        Fully-connected Overcomplete Autoencoder (AE)
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_4" type="checkbox" id="__nav_3_4" >
      
      <label class="md-nav__link" for="__nav_3_4">
        Improving Deep Learning with PyTorch
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Improving Deep Learning with PyTorch" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_4">
          <span class="md-nav__icon md-icon"></span>
          Improving Deep Learning with PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/derivative_gradient_jacobian/" class="md-nav__link">
        Derivative, Gradient and Jacobian
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/forwardpropagation_backpropagation_gradientdescent/" class="md-nav__link">
        Forward- and Backward-propagation and Gradient Descent (From Scratch FNN Regression)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/lr_scheduling/" class="md-nav__link">
        Learning Rate Scheduling
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/optimizers/" class="md-nav__link">
        Optimization Algorithms
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../boosting_models_pytorch/weight_initialization_activation_functions/" class="md-nav__link">
        Weight Initialization and Activation Functions
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_5" type="checkbox" id="__nav_3_5" >
      
      <label class="md-nav__link" for="__nav_3_5">
        Deep Reinforcement Learning with PyTorch
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Deep Reinforcement Learning with PyTorch" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_5">
          <span class="md-nav__icon md-icon"></span>
          Deep Reinforcement Learning with PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../deep_reinforcement_learning_pytorch/supervised_to_rl/" class="md-nav__link">
        Supervised Learning to Reinforcement Learning (RL)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../deep_reinforcement_learning_pytorch/bellman_mdp/" class="md-nav__link">
        Markov Decision Processes (MDP) and Bellman Equations
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../deep_reinforcement_learning_pytorch/dynamic_programming_frozenlake/" class="md-nav__link">
        Dynamic Programming
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_6" type="checkbox" id="__nav_3_6" >
      
      <label class="md-nav__link" for="__nav_3_6">
        From Scratch Deep Learning with Python/PyTorch
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="From Scratch Deep Learning with Python/PyTorch" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_6">
          <span class="md-nav__icon md-icon"></span>
          From Scratch Deep Learning with Python/PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../fromscratch/fromscratch_logistic_regression/" class="md-nav__link">
        From Scratch Logistic Regression Classification
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_7" type="checkbox" id="__nav_3_7" >
      
      <label class="md-nav__link" for="__nav_3_7">
        Compute Optimization
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Compute Optimization" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_7">
          <span class="md-nav__icon md-icon"></span>
          Compute Optimization
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../production_pytorch/speed_optimization_basics_numba/" class="md-nav__link">
        Speed Optimization Basics Numba
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      <label class="md-nav__link" for="__nav_4">
        Machine Learning (CPU/GPU)
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Machine Learning (CPU/GPU)" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Machine Learning (CPU/GPU)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../machine_learning/intro/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

          
            
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" >
      
      <label class="md-nav__link" for="__nav_4_2">
        RAPIDS cuDF
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="RAPIDS cuDF" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          RAPIDS cuDF
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../machine_learning/gpu/rapids_cudf/" class="md-nav__link">
        GPU DataFrames
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../machine_learning/gpu/gpu_fractional_differencing/" class="md-nav__link">
        GPU/CPU Fractional Differencing
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      <label class="md-nav__link" for="__nav_5">
        Programming
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Programming" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Programming
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/intro/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/cpp/cpp/" class="md-nav__link">
        C++
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/bash/bash/" class="md-nav__link">
        Bash
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/python/python/" class="md-nav__link">
        Python
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/r/r/" class="md-nav__link">
        R
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/javascript/javascript/" class="md-nav__link">
        Javascript
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/electron/electron/" class="md-nav__link">
        Electron
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/sympy/calculus_sympy/" class="md-nav__link">
        Sympy
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../programming/numpycupy/linalg_numpy_cupy/" class="md-nav__link">
        NumPy and CuPy
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      <label class="md-nav__link" for="__nav_6">
        Data Engineering
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Data Engineering" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Data Engineering
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_1" type="checkbox" id="__nav_6_1" >
      
      <label class="md-nav__link" for="__nav_6_1">
        Cassandra (NoSQL)
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Cassandra (NoSQL)" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_1">
          <span class="md-nav__icon md-icon"></span>
          Cassandra (NoSQL)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../data_engineering/nosql/cassandra/intro/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../data_engineering/nosql/cassandra/setting_up_cluster/" class="md-nav__link">
        Cassandra Cluster Setup
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" >
      
      <label class="md-nav__link" for="__nav_7">
        News
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="News" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          News
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/news/" class="md-nav__link">
        Welcome
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/dbs_gpu_rapids_nvidia_ensemble_frac_diff/" class="md-nav__link">
        Fractional Differencing with GPU (GFD), DBS and NVIDIA, September 2019
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/defence_and_science_technology_agency_dsta_nvidia_talk_2016_06/" class="md-nav__link">
        Deep Learning Introduction, Defence and Science Technology Agency (DSTA) and NVIDIA, June 2019
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/detect_waterbone_debris_ai_for_social_good_icml_2019_06/" class="md-nav__link">
        Oral Presentation for AI for Social Good Workshop ICML, June 2019
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/it_youth_leader_2019_03_11/" class="md-nav__link">
        IT Youth Leader of The Year 2019, March 2019
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/ammi_facebook_google_recap_2018_11_21/" class="md-nav__link">
        AMMI (AIMS) supported by Facebook and Google, November 2018
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/nanjing_next_nus_tsinghua_ai_finance_healthcare_2018_11_01/" class="md-nav__link">
        NExT++ AI in Healthcare and Finance, Nanjing, November 2018
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/facebook_pytorch_devcon_recap_2018_10_02/" class="md-nav__link">
        Recap of Facebook PyTorch Developer Conference, San Francisco, September 2018
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/facebook_pytorch_developer_conference_2018_09_05/" class="md-nav__link">
        Facebook PyTorch Developer Conference, San Francisco, September 2018
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/nvidia_nus_mit_datathon_2018_07_05/" class="md-nav__link">
        NUS-MIT-NUHS NVIDIA Image Recognition Workshop, Singapore, July 2018
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/deep_learning_wizard_1y_2018_06_01/" class="md-nav__link">
        Featured on PyTorch Website 2018
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/nvidia_self_driving_cars_talk_2017_06_21/" class="md-nav__link">
        NVIDIA Self Driving Cars & Healthcare Talk, Singapore, June 2017
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../news/deep_learning_wizard_nvidia_inception_2018_05_01/" class="md-nav__link">
        NVIDIA Inception Partner Status, Singapore, May 2017
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#about-feedforward-neural-network" class="md-nav__link">
    About Feedforward Neural Network
  </a>
  
    <nav class="md-nav" aria-label="About Feedforward Neural Network">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#logistic-regression-transition-to-neural-networks" class="md-nav__link">
    Logistic Regression Transition to Neural Networks
  </a>
  
    <nav class="md-nav" aria-label="Logistic Regression Transition to Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#logistic-regression-review" class="md-nav__link">
    Logistic Regression Review
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic-regression-problems" class="md-nav__link">
    Logistic Regression Problems
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#introducing-a-non-linear-function" class="md-nav__link">
    Introducing a Non-linear Function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#non-linear-function-in-depth" class="md-nav__link">
    Non-linear Function In-Depth
  </a>
  
    <nav class="md-nav" aria-label="Non-linear Function In-Depth">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sigmoid-logistic" class="md-nav__link">
    Sigmoid (Logistic)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tanh" class="md-nav__link">
    Tanh
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relus" class="md-nav__link">
    ReLUs
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-a-feedforward-neural-network-with-pytorch" class="md-nav__link">
    Building a Feedforward Neural Network with PyTorch
  </a>
  
    <nav class="md-nav" aria-label="Building a Feedforward Neural Network with PyTorch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-a-1-hidden-layer-feedforward-neural-network-sigmoid-activation" class="md-nav__link">
    Model A: 1 Hidden Layer Feedforward Neural Network (Sigmoid Activation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steps" class="md-nav__link">
    Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1-loading-mnist-train-dataset" class="md-nav__link">
    Step 1: Loading MNIST Train Dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-make-dataset-iterable" class="md-nav__link">
    Step 2: Make Dataset Iterable
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-create-model-class" class="md-nav__link">
    Step 3: Create Model Class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-instantiate-model-class" class="md-nav__link">
    Step 4: Instantiate Model Class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-5-instantiate-loss-class" class="md-nav__link">
    Step 5: Instantiate Loss Class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-6-instantiate-optimizer-class" class="md-nav__link">
    Step 6: Instantiate Optimizer Class
  </a>
  
    <nav class="md-nav" aria-label="Step 6: Instantiate Optimizer Class">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters-in-depth" class="md-nav__link">
    Parameters In-Depth
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-7-train-model" class="md-nav__link">
    Step 7: Train Model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-b-1-hidden-layer-feedforward-neural-network-tanh-activation" class="md-nav__link">
    Model B: 1 Hidden Layer Feedforward Neural Network (Tanh Activation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steps_1" class="md-nav__link">
    Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-c-1-hidden-layer-feedforward-neural-network-relu-activation" class="md-nav__link">
    Model C: 1 Hidden Layer Feedforward Neural Network (ReLU Activation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steps_2" class="md-nav__link">
    Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-d-2-hidden-layer-feedforward-neural-network-relu-activation" class="md-nav__link">
    Model D: 2 Hidden Layer Feedforward Neural Network (ReLU Activation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steps_3" class="md-nav__link">
    Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-e-3-hidden-layer-feedforward-neural-network-relu-activation" class="md-nav__link">
    Model E: 3 Hidden Layer Feedforward Neural Network (ReLU Activation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steps_4" class="md-nav__link">
    Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#general-comments-on-fnns" class="md-nav__link">
    General Comments on FNNs
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-building-a-feedforward-neural-network-with-pytorch-gpu" class="md-nav__link">
    3. Building a Feedforward Neural Network with PyTorch (GPU)
  </a>
  
    <nav class="md-nav" aria-label="3. Building a Feedforward Neural Network with PyTorch (GPU)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#steps_5" class="md-nav__link">
    Steps
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    Citation
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/ritchieng/deep-learning-wizard/edit/master/docs/deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <h1 id="feedforward-neural-network-with-pytorch">Feedforward Neural Network with PyTorch<a class="headerlink" href="#feedforward-neural-network-with-pytorch" title="Permanent link">&para;</a></h1>
<div class="admonition tip">
<p class="admonition-title">Run Jupyter Notebook</p>
<p>You can run the code for this section in this <a href="https://github.com/ritchieng/deep-learning-wizard/blob/master/docs/deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork.ipynb">jupyter notebook link</a>.</p>
</div>
<h2 id="about-feedforward-neural-network">About Feedforward Neural Network<a class="headerlink" href="#about-feedforward-neural-network" title="Permanent link">&para;</a></h2>
<h3 id="logistic-regression-transition-to-neural-networks">Logistic Regression Transition to Neural Networks<a class="headerlink" href="#logistic-regression-transition-to-neural-networks" title="Permanent link">&para;</a></h3>
<h4 id="logistic-regression-review">Logistic Regression Review<a class="headerlink" href="#logistic-regression-review" title="Permanent link">&para;</a></h4>
<p><img alt="" src="../images/cross_entropy_final_4.png" /></p>
<div class="admonition note">
<p class="admonition-title">Define logistic regression model</p>
<p>Import our relevant torch modules.
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</code></pre></div></p>
<p>Define our model class.
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">LogisticRegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogisticRegressionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div></p>
<p>Instantiate the logistic regression model.
<div class="highlight"><pre><span></span><code><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegressionModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
</code></pre></div></p>
<p>When we inspect the model, we would have an input size of 784 (derived from 28 x 28) and output size of 10 (which is the number of classes we are classifying from 0 to 9).
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="n">LogisticRegressionModel</span><span class="p">(</span>
  <span class="p">(</span><span class="n">linear</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>
<h4 id="logistic-regression-problems">Logistic Regression Problems<a class="headerlink" href="#logistic-regression-problems" title="Permanent link">&para;</a></h4>
<ul>
<li>Can represent <strong>linear</strong> functions well<ul>
<li><span class="arithmatex">\(y = 2x + 3\)</span></li>
<li><span class="arithmatex">\(y = x_1 + x_2\)</span></li>
<li><span class="arithmatex">\(y = x_1 + 3x_2 + 4x_3\)</span></li>
</ul>
</li>
<li>Cannot represent <strong>non-linear</strong> functions<ul>
<li><span class="arithmatex">\(y = 4x_1 + 2x_2^2 +3x_3^3\)</span></li>
<li><span class="arithmatex">\(y = x_1x_2\)</span></li>
</ul>
</li>
</ul>
<h3 id="introducing-a-non-linear-function">Introducing a Non-linear Function<a class="headerlink" href="#introducing-a-non-linear-function" title="Permanent link">&para;</a></h3>
<p><img alt="" src="../images/logistic_regression_comparison_nn5.png" /></p>
<h3 id="non-linear-function-in-depth">Non-linear Function In-Depth<a class="headerlink" href="#non-linear-function-in-depth" title="Permanent link">&para;</a></h3>
<ul>
<li>Function: takes a number &amp; perform mathematical operation</li>
<li>Common Types of Non-linearity<ul>
<li>ReLUs (Rectified Linear Units)      </li>
<li>Sigmoid</li>
<li>Tanh</li>
</ul>
</li>
</ul>
<h4 id="sigmoid-logistic">Sigmoid (Logistic)<a class="headerlink" href="#sigmoid-logistic" title="Permanent link">&para;</a></h4>
<ul>
<li><span class="arithmatex">\(\sigma(x) = \frac{1}{1 + e^{-x}}\)</span></li>
<li>Input number <span class="arithmatex">\(\rightarrow\)</span> [0, 1]<ul>
<li>Large negative number <span class="arithmatex">\(\rightarrow\)</span> 0</li>
<li>Large positive number <span class="arithmatex">\(\rightarrow\)</span> 1</li>
</ul>
</li>
<li>Cons: <ol>
<li>Activation saturates at 0 or 1 with <strong>gradients <span class="arithmatex">\(\approx\)</span> 0</strong><ul>
<li>No signal to update weights <span class="arithmatex">\(\rightarrow\)</span> <strong>cannot learn</strong></li>
<li>Solution: Have to carefully initialize weights to prevent this</li>
</ul>
</li>
<li>Outputs not centered around 0 <ul>
<li>If output always positive <span class="arithmatex">\(\rightarrow\)</span> gradients always positive or negative <span class="arithmatex">\(\rightarrow\)</span> <strong>bad for gradient updates</strong> </li>
</ul>
</li>
</ol>
</li>
</ul>
<h4 id="tanh">Tanh<a class="headerlink" href="#tanh" title="Permanent link">&para;</a></h4>
<ul>
<li><span class="arithmatex">\(\tanh(x) = 2 \sigma(2x) -1\)</span><ul>
<li>A scaled sigmoid function</li>
</ul>
</li>
<li>Input number <span class="arithmatex">\(\rightarrow\)</span> [-1, 1]</li>
<li>Cons: <ol>
<li>Activation saturates at 0 or 1 with <strong>gradients <span class="arithmatex">\(\approx\)</span> 0</strong><ul>
<li>No signal to update weights <span class="arithmatex">\(\rightarrow\)</span> <strong>cannot learn</strong></li>
<li><strong>Solution</strong>: Have to carefully initialize weights to prevent this</li>
</ul>
</li>
</ol>
</li>
</ul>
<h4 id="relus">ReLUs<a class="headerlink" href="#relus" title="Permanent link">&para;</a></h4>
<ul>
<li><span class="arithmatex">\(f(x) = \max(0, x)\)</span></li>
<li>Pros:<ol>
<li>Accelerates convergence <span class="arithmatex">\(\rightarrow\)</span> <strong>train faster</strong></li>
<li><strong>Less computationally expensive operation</strong> compared to Sigmoid/Tanh exponentials</li>
</ol>
</li>
<li>Cons:<ol>
<li>Many ReLU units "die" <span class="arithmatex">\(\rightarrow\)</span> <strong>gradients = 0</strong> forever<ul>
<li><strong>Solution</strong>: careful learning rate choice</li>
</ul>
</li>
</ol>
</li>
</ul>
<h2 id="building-a-feedforward-neural-network-with-pytorch">Building a Feedforward Neural Network with PyTorch<a class="headerlink" href="#building-a-feedforward-neural-network-with-pytorch" title="Permanent link">&para;</a></h2>
<h3 id="model-a-1-hidden-layer-feedforward-neural-network-sigmoid-activation">Model A: 1 Hidden Layer Feedforward Neural Network (Sigmoid Activation)<a class="headerlink" href="#model-a-1-hidden-layer-feedforward-neural-network-sigmoid-activation" title="Permanent link">&para;</a></h3>
<p><img alt="" src="../images/nn1.png" /></p>
<h3 id="steps">Steps<a class="headerlink" href="#steps" title="Permanent link">&para;</a></h3>
<ul>
<li>Step 1: Load Dataset</li>
<li>Step 2: Make Dataset Iterable</li>
<li>Step 3: Create Model Class</li>
<li>Step 4: Instantiate Model Class</li>
<li>Step 5: Instantiate Loss Class</li>
<li>Step 6: Instantiate Optimizer Class</li>
<li>Step 7: Train Model</li>
</ul>
<h3 id="step-1-loading-mnist-train-dataset">Step 1: Loading MNIST Train Dataset<a class="headerlink" href="#step-1-loading-mnist-train-dataset" title="Permanent link">&para;</a></h3>
<div class="admonition note">
<p class="admonition-title">Images from 1 to 9</p>
<p>Similar to what we did in logistic regression, we will be using the same MNIST dataset where we load our training and testing datasets.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dsets</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>
</code></pre></div>
</div>
<h3 id="step-2-make-dataset-iterable">Step 2: Make Dataset Iterable<a class="headerlink" href="#step-2-make-dataset-iterable" title="Permanent link">&para;</a></h3>
<div class="admonition note">
<p class="admonition-title">Batch sizes and iterations</p>
<p>Because we have 60000 training samples (images), we need to split them up to small groups (batches) and pass these batches of samples to our feedforward neural network subsesquently.</p>
<p>There are a few reasons why we split them into batches. Passing your whole dataset as a single batch would:</p>
<p>(1) require a lot of RAM/VRAM on your CPU/GPU and this might result in Out-of-Memory (OOM) errors. </p>
<p>(2) cause unstable training if you just use all the errors accumulated in 60,000 images to update the model rather than gradually update the model. In layman terms, imagine you accumulated errors for a student taking an exam with 60,000 questions and punish the student all at the same time. It is much harder for the student to learn compared to letting the student learn it made mistakes and did well in smaller batches of questions like mini-tests!</p>
<p>If we have 60,000 images and we want a batch size of 100, then we would have 600 iterations where each iteration involves passing 600 images to the model and getting their respective predictions. </p>
<div class="highlight"><pre><span></span><code><span class="mi">60000</span> <span class="o">/</span> <span class="mi">100</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="mf">600.0</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Epochs</p>
<p>An epoch means that you have successfully passed the whole training set, 60,000 images, to the model. Continuing our example above, an epoch consists of 600 iterations.</p>
<p>If we want to go through the whole dataset 5 times (5 epochs) for the model to learn, then we need 3000 iterations (600 x 5). </p>
<div class="highlight"><pre><span></span><code><span class="mi">600</span> <span class="o">*</span> <span class="mi">5</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="mf">3000.0</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Bringing batch size, iterations and epochs together</p>
<p>As we have gone through above, we want to have 5 epochs, where each epoch would have 600 iterations and each iteration has a batch size of 100.</p>
<p>Because we want 5 epochs, we need a total of 3000 iterations.</p>
<div class="highlight"><pre><span></span><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="n">n_iters</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
</div>
<h3 id="step-3-create-model-class">Step 3: Create Model Class<a class="headerlink" href="#step-3-create-model-class" title="Permanent link">&para;</a></h3>
<div class="admonition note">
<p class="admonition-title">Creating our feedforward neural network</p>
<p>Compared to logistic regression with only a single linear layer, we know for an FNN we need an additional linear layer and non-linear layer. </p>
<p>This translates to just 4 more lines of code! </p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">FeedforwardNeuralNetModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FeedforwardNeuralNetModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Linear function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span> 

        <span class="c1"># Non-linearity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

        <span class="c1"># Linear function (readout)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>  

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Linear function  # LINEAR</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Non-linearity  # NON-LINEAR</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># Linear function (readout)  # LINEAR</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div>
</div>
<h3 id="step-4-instantiate-model-class">Step 4: Instantiate Model Class<a class="headerlink" href="#step-4-instantiate-model-class" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Input</strong> dimension: <strong>784</strong> <ul>
<li>Size of image</li>
<li><span class="arithmatex">\(28 \times 28 = 784\)</span></li>
</ul>
</li>
<li><strong>Output</strong> dimension: <strong>10</strong><ul>
<li>0, 1, 2, 3, 4, 5, 6, 7, 8, 9</li>
</ul>
</li>
<li><strong>Hidden</strong> dimension: <strong>100</strong><ul>
<li>Can be any number</li>
<li>Similar term<ul>
<li>Number of neurons</li>
<li>Number of non-linear activation functions</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Instantiating our model class</p>
<p>Our input size is determined by the size of the image (numbers ranging from 0 to 9) which has a width of 28 pixels and a height of 28 pixels. Hence the size of our input is 784 (28 x 28).</p>
<p>Our output size is what we are trying to predict. When we pass an image to our model, it will try to predict if it's 0, 1, 2, 3, 4, 5, 6, 7, 8, or 9. That is a total of 10 classes, hence we have an output size of 10.</p>
<p>Now the tricky part is in determining our hidden layer size, that is the size of our first linear layer prior to the non-linear layer. This can be any number, a larger number implies a bigger model with more parameters. Intuitively we think a bigger model equates to a better model, but a bigger model requires more training samples to learn and converge to a good model (also called curse of dimensionality). Hence, it is wise to pick the model size for the problem at hand. Because it is a simple problem of recognizing digits, we typically would not need a big model to achieve state-of-the-art results.</p>
<p>On the flipside, too small of a hidden size would mean there would be insufficient model capacity to predict competently. In layman terms, too small of a capacity implies a smaller brain capacity so no matter how many training samples you give it, it has a maximum capacity in terms of its predictive power. </p>
<div class="highlight"><pre><span></span><code><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">FeedforwardNeuralNetModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
</code></pre></div>
</div>
<h3 id="step-5-instantiate-loss-class">Step 5: Instantiate Loss Class<a class="headerlink" href="#step-5-instantiate-loss-class" title="Permanent link">&para;</a></h3>
<ul>
<li>Feedforward Neural Network: <strong>Cross Entropy Loss</strong><ul>
<li><em>Logistic Regression</em>: <strong>Cross Entropy Loss</strong></li>
<li><em>Linear Regression</em>: <strong>MSE</strong></li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Loss class</p>
<p>This is exactly the same as what we did in logistic regression. Because we are going through a classification problem, cross entropy function is required to compute the loss between our softmax outputs and our binary labels.</p>
<div class="highlight"><pre><span></span><code><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</code></pre></div>
</div>
<h3 id="step-6-instantiate-optimizer-class">Step 6: Instantiate Optimizer Class<a class="headerlink" href="#step-6-instantiate-optimizer-class" title="Permanent link">&para;</a></h3>
<ul>
<li>Simplified equation<ul>
<li><span class="arithmatex">\(\theta = \theta - \eta \cdot \nabla_\theta\)</span><ul>
<li><span class="arithmatex">\(\theta\)</span>: parameters (our tensors with gradient accumulation capabilities)</li>
<li><span class="arithmatex">\(\eta\)</span>: learning rate (how fast we want to learn)</li>
<li><span class="arithmatex">\(\nabla_\theta\)</span>: parameters' gradients</li>
</ul>
</li>
</ul>
</li>
<li>Even simplier equation<ul>
<li><code>parameters = parameters - learning_rate * parameters_gradients</code></li>
<li><strong>At every iteration, we update our model's parameters</strong></li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Optimizer class</p>
<p>Learning rate determines how fast the algorithm learns. Too small and the algorithm learns too slowly, too large and the algorithm learns too fast resulting in instabilities.</p>
<p>Intuitively, we would think a larger learning rate would be better because we learn faster. But that's not true. Imagine we pass 10 images to a human to learn how to recognize whether the image is a hot dog or not, and it got half right and half wrong. </p>
<p>A well defined learning rate (neither too small or large) is equivalent to rewarding the human with a sweet for getting the first half right, and punishing the other half the human got wrong with a smack on the palm. </p>
<p>A large learning rate would be equivalent to feeding a thousand sweets to the human and smacking a thousand times on the human's palm. This would lead in a very unstable learning environment. Similarly, we will observe that the algorithm's convergence path will be extremely unstable if you use a large learning rate without reducing it subsequently. </p>
<p>We are using an optimization algorithm called Stochastic Gradient Descent (SGD) which is essentially what we covered above on calculating the parameters' gradients multiplied by the learning rate then using it to update our parameters gradually. There's an in-depth analysis of various optimization algorithms on top of SGD in another section.</p>
<div class="highlight"><pre><span></span><code><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>  
</code></pre></div>
</div>
<h4 id="parameters-in-depth">Parameters In-Depth<a class="headerlink" href="#parameters-in-depth" title="Permanent link">&para;</a></h4>
<div class="admonition note">
<p class="admonition-title">Linear layers' parameters</p>
<p>In a simple linear layer it's <span class="arithmatex">\(Y = AX + B\)</span>, and our parameters are <span class="arithmatex">\(A\)</span> and bias <span class="arithmatex">\(B\)</span>. </p>
<p>Hence, each linear layer would have 2 groups of parameters  <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(B\)</span>. It is critical to take note that our non-linear layers have no parameters to update. They are merely mathematical functions performed on <span class="arithmatex">\(Y\)</span>, the output of our linear layers.</p>
<p>This would return a Python generator object, so you need to call list on the generator object to access anything meaningful.
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</code></pre></div></p>
<p>Here we call list on the generator object and getting the length of the list. This would return 4 because we've 2 linear layers, and each layer has 2 groups of parameters <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(b\)</span>.</p>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())))</span>
</code></pre></div>
<p>Our first linear layer parameters, <span class="arithmatex">\(A_1\)</span>, would be of size 100 x 784. This is because we've an input size of 784 (28 x 28) and a hidden size of 100.
<div class="highlight"><pre><span></span><code><span class="c1"># FC 1 Parameters </span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</code></pre></div></p>
<p>Our first linear layer bias parameters, <span class="arithmatex">\(B_1\)</span>, would be of size 100 which is our hidden size.
<div class="highlight"><pre><span></span><code><span class="c1"># FC 1 Bias Parameters</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</code></pre></div></p>
<p>Our second linear layer is our readout layer, where the parameters <span class="arithmatex">\(A_2\)</span> would be of size 10 x 100. This is because our output size is 10 and hidden size is 100.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># FC 2 Parameters</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</code></pre></div>
<p>Likewise our readout layer's bias <span class="arithmatex">\(B_1\)</span> would just be 10, the size of our output.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># FC 2 Bias Parameters</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</code></pre></div>
<p>The diagram below shows the interaction amongst our input <span class="arithmatex">\(X\)</span> and our linear layers' parameters <span class="arithmatex">\(A_1\)</span>, <span class="arithmatex">\(B_1\)</span>, <span class="arithmatex">\(A_2\)</span>, and <span class="arithmatex">\(B_2\)</span> to reach to the final size of 10 x 1.</p>
<p>If you're still unfamiliar with matrix product, go ahead and review the previous quick lesson where we covered it in <a href="https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_logistic_regression/#step-6-instantiate-optimizer-class">logistic regression</a>.</p>
</div>
<div class="highlight"><pre><span></span><code><span class="o">&lt;</span><span class="n">generator</span> <span class="nb">object</span> <span class="n">Module</span><span class="o">.</span><span class="n">parameters</span> <span class="n">at</span> <span class="mh">0x7f1d530fa678</span><span class="o">&gt;</span>
<span class="mi">4</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span>
</code></pre></div>
<p><img alt="" src="../images/nn1_params3.png" /></p>
<h3 id="step-7-train-model">Step 7: Train Model<a class="headerlink" href="#step-7-train-model" title="Permanent link">&para;</a></h3>
<ul>
<li>Process <ol>
<li>Convert inputs to tensors with gradient accumulation capabilities</li>
<li>Clear gradient buffers</li>
<li>Get output given inputs </li>
<li>Get loss</li>
<li>Get gradients w.r.t. parameters</li>
<li>Update parameters using gradients<ul>
<li><code>parameters = parameters - learning_rate * parameters_gradients</code></li>
</ul>
</li>
<li>REPEAT</li>
</ol>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">7-step training process</p>
<div class="highlight"><pre><span></span><code><span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="c1"># Load images with gradient accumulation capabilities</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

        <span class="c1"># Clear gradients w.r.t. parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass to get output/logits</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Getting gradients w.r.t. parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updating parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate Accuracy         </span>
            <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Iterate through test dataset</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="c1"># Load images with gradient accumulation capabilities</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

                <span class="c1"># Forward pass only to get logits/output</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

                <span class="c1"># Get predictions from the maximum value</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Total number of labels</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># Total correct predictions</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

            <span class="c1"># Print Loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="s1">. Loss: </span><span class="si">{}</span><span class="s1">. Accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">Iteration</span><span class="p">:</span> <span class="mf">500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.6457265615463257</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">85</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.39627206325531006</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">89</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2831554412841797</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">90</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4409525394439697</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">91</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2397005707025528</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">91</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">3000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3160165846347809</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">91</span>
</code></pre></div>
<h3 id="model-b-1-hidden-layer-feedforward-neural-network-tanh-activation">Model B: 1 Hidden Layer Feedforward Neural Network (Tanh Activation)<a class="headerlink" href="#model-b-1-hidden-layer-feedforward-neural-network-tanh-activation" title="Permanent link">&para;</a></h3>
<p><img alt="" src="../images/nn1.png" /></p>
<h3 id="steps_1">Steps<a class="headerlink" href="#steps_1" title="Permanent link">&para;</a></h3>
<ul>
<li>Step 1: Load Dataset</li>
<li>Step 2: Make Dataset Iterable</li>
<li><strong>Step 3: Create Model Class</strong></li>
<li>Step 4: Instantiate Model Class</li>
<li>Step 5: Instantiate Loss Class</li>
<li>Step 6: Instantiate Optimizer Class</li>
<li>Step 7: Train Model</li>
</ul>
<div class="admonition note">
<p class="admonition-title">1-layer FNN with Tanh Activation</p>
<p>The only difference here compared to previously is that we are using Tanh activation instead of Sigmoid activation. This affects step 3.
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dsets</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 1: LOADING DATASET</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 2: MAKING DATASET ITERABLE</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="n">n_iters</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 3: CREATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="k">class</span> <span class="nc">FeedforwardNeuralNetModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FeedforwardNeuralNetModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Linear function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span> 
        <span class="c1"># Non-linearity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="c1"># Linear function (readout)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>  

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Linear function</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Non-linearity</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="c1"># Linear function (readout)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 4: INSTANTIATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">FeedforwardNeuralNetModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 5: INSTANTIATE LOSS CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 7: TRAIN THE MODEL</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="c1"># Load images with gradient accumulation capabilities</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

        <span class="c1"># Clear gradients w.r.t. parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass to get output/logits</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Getting gradients w.r.t. parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updating parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate Accuracy         </span>
            <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Iterate through test dataset</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="c1"># Load images with gradient accumulation capabilities</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

                <span class="c1"># Forward pass only to get logits/output</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

                <span class="c1"># Get predictions from the maximum value</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Total number of labels</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># Total correct predictions</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

            <span class="c1"># Print Loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="s1">. Loss: </span><span class="si">{}</span><span class="s1">. Accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="n">Iteration</span><span class="p">:</span> <span class="mf">500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4128190577030182</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">91</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.14497484266757965</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">92</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.272532194852829</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">93</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2758277952671051</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">94</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1603182554244995</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">94</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">3000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.08848697692155838</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">95</span>
</code></pre></div>
<h3 id="model-c-1-hidden-layer-feedforward-neural-network-relu-activation">Model C: 1 Hidden Layer Feedforward Neural Network (ReLU Activation)<a class="headerlink" href="#model-c-1-hidden-layer-feedforward-neural-network-relu-activation" title="Permanent link">&para;</a></h3>
<p><img alt="" src="../images/nn1.png" /></p>
<h3 id="steps_2">Steps<a class="headerlink" href="#steps_2" title="Permanent link">&para;</a></h3>
<ul>
<li>Step 1: Load Dataset</li>
<li>Step 2: Make Dataset Iterable</li>
<li><strong>Step 3: Create Model Class</strong></li>
<li>Step 4: Instantiate Model Class</li>
<li>Step 5: Instantiate Loss Class</li>
<li>Step 6: Instantiate Optimizer Class</li>
<li>Step 7: Train Model</li>
</ul>
<div class="admonition note">
<p class="admonition-title">1-layer FNN with ReLU Activation</p>
<p>The only difference again is in using ReLU activation and it affects step 3.
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dsets</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 1: LOADING DATASET</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 2: MAKING DATASET ITERABLE</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="n">n_iters</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 3: CREATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="k">class</span> <span class="nc">FeedforwardNeuralNetModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FeedforwardNeuralNetModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Linear function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span> 
        <span class="c1"># Non-linearity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="c1"># Linear function (readout)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>  

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Linear function</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Non-linearity</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="c1"># Linear function (readout)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 4: INSTANTIATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">FeedforwardNeuralNetModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 5: INSTANTIATE LOSS CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>


<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 7: TRAIN THE MODEL</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="c1"># Load images with gradient accumulation capabilities</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

        <span class="c1"># Clear gradients w.r.t. parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass to get output/logits</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Getting gradients w.r.t. parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updating parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate Accuracy         </span>
            <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Iterate through test dataset</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="c1"># Load images with gradient accumulation capabilities</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

                <span class="c1"># Forward pass only to get logits/output</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

                <span class="c1"># Get predictions from the maximum value</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Total number of labels</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># Total correct predictions</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

            <span class="c1"># Print Loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="s1">. Loss: </span><span class="si">{}</span><span class="s1">. Accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="n">Iteration</span><span class="p">:</span> <span class="mf">500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3179700970649719</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">91</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.17288273572921753</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">93</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.16829034686088562</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">94</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.25494423508644104</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">94</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.16818439960479736</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">95</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">3000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.11110792309045792</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">95</span>
</code></pre></div>
<h3 id="model-d-2-hidden-layer-feedforward-neural-network-relu-activation">Model D: 2 Hidden Layer Feedforward Neural Network (ReLU Activation)<a class="headerlink" href="#model-d-2-hidden-layer-feedforward-neural-network-relu-activation" title="Permanent link">&para;</a></h3>
<p><img alt="" src="../images/nn2.png" /></p>
<h3 id="steps_3">Steps<a class="headerlink" href="#steps_3" title="Permanent link">&para;</a></h3>
<ul>
<li>Step 1: Load Dataset</li>
<li>Step 2: Make Dataset Iterable</li>
<li><strong>Step 3: Create Model Class</strong></li>
<li>Step 4: Instantiate Model Class</li>
<li>Step 5: Instantiate Loss Class</li>
<li>Step 6: Instantiate Optimizer Class</li>
<li>Step 7: Train Model</li>
</ul>
<div class="admonition note">
<p class="admonition-title">2-layer FNN with ReLU Activation</p>
<p>This is a bigger difference that increases your model's capacity by adding another linear layer and non-linear layer which affects step 3.
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dsets</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 1: LOADING DATASET</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 2: MAKING DATASET ITERABLE</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="n">n_iters</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 3: CREATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="k">class</span> <span class="nc">FeedforwardNeuralNetModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FeedforwardNeuralNetModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Linear function 1: 784 --&gt; 100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span> 
        <span class="c1"># Non-linearity 1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="c1"># Linear function 2: 100 --&gt; 100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="c1"># Non-linearity 2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="c1"># Linear function 3 (readout): 100 --&gt; 10</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>  

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Linear function 1</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Non-linearity 1</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># Linear function 2</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="c1"># Non-linearity 2</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># Linear function 3 (readout)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 4: INSTANTIATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">FeedforwardNeuralNetModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 5: INSTANTIATE LOSS CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>


<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 7: TRAIN THE MODEL</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="c1"># Load images with gradient accumulation capabilities</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>

        <span class="c1"># Clear gradients w.r.t. parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass to get output/logits</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Getting gradients w.r.t. parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updating parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate Accuracy         </span>
            <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Iterate through test dataset</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="c1"># Load images with gradient accumulation capabilities</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

                <span class="c1"># Forward pass only to get logits/output</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

                <span class="c1"># Get predictions from the maximum value</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Total number of labels</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># Total correct predictions</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

            <span class="c1"># Print Loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="s1">. Loss: </span><span class="si">{}</span><span class="s1">. Accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
</code></pre></div></p>
</div>
<div class="highlight"><pre><span></span><code><span class="n">Iteration</span><span class="p">:</span> <span class="mf">500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2995373010635376</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">91</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3924565613269806</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">93</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1283276081085205</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">94</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.10905527323484421</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">95</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.11943754553794861</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">96</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">3000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.15632082521915436</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">96</span>
</code></pre></div>
<h3 id="model-e-3-hidden-layer-feedforward-neural-network-relu-activation">Model E: 3 Hidden Layer Feedforward Neural Network (ReLU Activation)<a class="headerlink" href="#model-e-3-hidden-layer-feedforward-neural-network-relu-activation" title="Permanent link">&para;</a></h3>
<p><img alt="" src="./images/nn3.png&quot;" /></p>
<h3 id="steps_4">Steps<a class="headerlink" href="#steps_4" title="Permanent link">&para;</a></h3>
<ul>
<li>Step 1: Load Dataset</li>
<li>Step 2: Make Dataset Iterable</li>
<li><strong>Step 3: Create Model Class</strong></li>
<li>Step 4: Instantiate Model Class</li>
<li>Step 5: Instantiate Loss Class</li>
<li>Step 6: Instantiate Optimizer Class</li>
<li>Step 7: Train Model</li>
</ul>
<div class="admonition note">
<p class="admonition-title">3-layer FNN with ReLU Activation</p>
<p>Let's add one more layer! Bigger model capacity. But will it be better? Remember what we talked about on curse of dimensionality?</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dsets</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 1: LOADING DATASET</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 2: MAKING DATASET ITERABLE</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="n">n_iters</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 3: CREATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="k">class</span> <span class="nc">FeedforwardNeuralNetModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FeedforwardNeuralNetModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Linear function 1: 784 --&gt; 100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span> 
        <span class="c1"># Non-linearity 1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="c1"># Linear function 2: 100 --&gt; 100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="c1"># Non-linearity 2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="c1"># Linear function 3: 100 --&gt; 100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="c1"># Non-linearity 3</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="c1"># Linear function 4 (readout): 100 --&gt; 10</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>  

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Linear function 1</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Non-linearity 1</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># Linear function 2</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="c1"># Non-linearity 2</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># Linear function 2</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="c1"># Non-linearity 2</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># Linear function 4 (readout)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 4: INSTANTIATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">FeedforwardNeuralNetModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 5: INSTANTIATE LOSS CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>


<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 7: TRAIN THE MODEL</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="c1"># Load images with gradient accumulation capabilities</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

        <span class="c1"># Clear gradients w.r.t. parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass to get output/logits</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Getting gradients w.r.t. parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updating parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate Accuracy         </span>
            <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Iterate through test dataset</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="c1"># Load images with gradient accumulation capabilities</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

                <span class="c1"># Forward pass only to get logits/output</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

                <span class="c1"># Get predictions from the maximum value</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Total number of labels</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># Total correct predictions</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

            <span class="c1"># Print Loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="s1">. Loss: </span><span class="si">{}</span><span class="s1">. Accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">Iteration</span><span class="p">:</span> <span class="mf">500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.33234935998916626</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">89</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3098006248474121</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">94</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.12461677193641663</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">95</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.14346086978912354</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">96</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.03763459622859955</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">96</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">3000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1397182047367096</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">97</span>
</code></pre></div>
<h3 id="general-comments-on-fnns">General Comments on FNNs<a class="headerlink" href="#general-comments-on-fnns" title="Permanent link">&para;</a></h3>
<ul>
<li>2 ways to expand a neural network<ul>
<li>More non-linear activation units (neurons)</li>
<li>More hidden layers </li>
</ul>
</li>
<li>Cons<ul>
<li>Need a larger dataset<ul>
<li>Curse of dimensionality</li>
</ul>
</li>
<li>Does not necessarily mean higher accuracy</li>
</ul>
</li>
</ul>
<h2 id="3-building-a-feedforward-neural-network-with-pytorch-gpu">3. Building a Feedforward Neural Network with PyTorch (GPU)<a class="headerlink" href="#3-building-a-feedforward-neural-network-with-pytorch-gpu" title="Permanent link">&para;</a></h2>
<p><img alt="" src="../images/nn3.png" /></p>
<p>GPU: 2 things must be on GPU
- <code>model</code>
- <code>tensors</code></p>
<h3 id="steps_5">Steps<a class="headerlink" href="#steps_5" title="Permanent link">&para;</a></h3>
<ul>
<li>Step 1: Load Dataset</li>
<li>Step 2: Make Dataset Iterable</li>
<li>Step 3: Create Model Class</li>
<li><strong>Step 4: Instantiate Model Class</strong></li>
<li>Step 5: Instantiate Loss Class</li>
<li>Step 6: Instantiate Optimizer Class</li>
<li><strong>Step 7: Train Model</strong></li>
</ul>
<div class="admonition note">
<p class="admonition-title">3-layer FNN with ReLU Activation on GPU</p>
<p>Only step 4 and 7 of the CPU code will be affected and it's a simple change.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dsets</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 1: LOADING DATASET</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> 
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 2: MAKING DATASET ITERABLE</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="n">n_iters</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 3: CREATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="k">class</span> <span class="nc">FeedforwardNeuralNetModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FeedforwardNeuralNetModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Linear function 1: 784 --&gt; 100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span> 
        <span class="c1"># Non-linearity 1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="c1"># Linear function 2: 100 --&gt; 100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="c1"># Non-linearity 2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="c1"># Linear function 3: 100 --&gt; 100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="c1"># Non-linearity 3</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="c1"># Linear function 4 (readout): 100 --&gt; 10</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>  

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Linear function 1</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Non-linearity 1</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># Linear function 2</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="c1"># Non-linearity 2</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># Linear function 2</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="c1"># Non-linearity 2</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># Linear function 4 (readout)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 4: INSTANTIATE MODEL CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">FeedforwardNeuralNetModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

<span class="c1">#######################</span>
<span class="c1">#  USE GPU FOR MODEL  #</span>
<span class="c1">#######################</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 5: INSTANTIATE LOSS CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>


<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">STEP 7: TRAIN THE MODEL</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>

        <span class="c1">#######################</span>
        <span class="c1">#  USE GPU FOR MODEL  #</span>
        <span class="c1">#######################</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Clear gradients w.r.t. parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass to get output/logits</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Getting gradients w.r.t. parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updating parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate Accuracy         </span>
            <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Iterate through test dataset</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="c1">#######################</span>
                <span class="c1">#  USE GPU FOR MODEL  #</span>
                <span class="c1">#######################</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># Forward pass only to get logits/output</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

                <span class="c1"># Get predictions from the maximum value</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Total number of labels</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1">#######################</span>
                <span class="c1">#  USE GPU FOR MODEL  #</span>
                <span class="c1">#######################</span>
                <span class="c1"># Total correct predictions</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                    <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="o">==</span> <span class="n">labels</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

            <span class="c1"># Print Loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="s1">. Loss: </span><span class="si">{}</span><span class="s1">. Accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">Iteration</span><span class="p">:</span> <span class="mf">500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3877025246620178</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">90</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1337055265903473</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">93</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">1500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2038637101650238</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">95</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.17892278730869293</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">95</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">2500.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.14455552399158478</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">96</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mf">3000.</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.024540524929761887</span><span class="o">.</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mi">96</span>
</code></pre></div>
<div class="admonition tip">
<p class="admonition-title">Alternative Term of Neural Network</p>
<p>The alternative term is <strong>Universal Function Approximator</strong>. This is because ultimately we are trying to find a function that maps our input, <span class="arithmatex">\(X\)</span>, to our output, <span class="arithmatex">\(y\)</span>. </p>
</div>
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h2>
<p>We've learnt to...</p>
<div class="admonition success">
<p class="admonition-title">Success</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Logistic Regression Problems</strong> for Non-Linear Functions Representation<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Cannot represent <strong>non-linear</strong> functions<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> $ y = 4x_1 + 2x_2^2 +3x_3^3 $</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> $ y = x_1x_2$</li>
</ul>
</li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Introduced <strong>Non-Linearity</strong> to Logistic Regression to form a Neural Network</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Types</strong> of Non-Linearity<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Sigmoid</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Tanh</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> ReLU</li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Feedforward Neural Network <strong>Models</strong><ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Model A: 1 hidden layer (<strong>sigmoid</strong> activation)</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Model B: 1 hidden layer (<strong>tanh</strong> activation)</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Model C: 1 hidden layer (<strong>ReLU</strong> activation)</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Model D: <strong>2 hidden</strong> layers (ReLU activation)</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Model E: <strong>3 hidden</strong> layers (ReLU activation)</li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Models Variation in <strong>Code</strong><ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Modifying only step 3</li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Ways to Expand Model’s <strong>Capacity</strong><ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> More non-linear activation units (<strong>neurons</strong>)</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> More hidden <strong>layers</strong></li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Cons</strong> of Expanding Capacity<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Need more <strong>data</strong></li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Does not necessarily mean higher <strong>accuracy</strong></li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>GPU</strong> Code<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 2 things on GPU<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>model</strong></li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>tensors with gradient accumulation capabilities</strong></li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Modifying only <strong>Step 4 &amp; Step 7</strong></li>
</ul>
</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>7 Step</strong> Model Building Recap<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 1: Load Dataset</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 2: Make Dataset Iterable</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 3: Create Model Class</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 4: Instantiate Model Class</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 5: Instantiate Loss Class</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 6: Instantiate Optimizer Class</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Step 7: Train Model</li>
</ul>
</li>
</ul>
</div>
<h2 id="citation">Citation<a class="headerlink" href="#citation" title="Permanent link">&para;</a></h2>
<p>If you have found these useful in your research, presentations, school work, projects or workshops, feel free to cite using this DOI.</p>
<p><a href="https://zenodo.org/badge/latestdoi/139945544"><img alt="DOI" src="https://zenodo.org/badge/139945544.svg" /></a></p>
                
              
              
                


  <h2 id="__comments">Comments</h2>
  <div id="disqus_thread"></div>
  <script>var disqus_config=function(){this.page.url="https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork/",this.page.identifier="deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork/"};window.addEventListener("load",function(){var e=document,i=e.createElement("script");i.src="//deep-learning-wizard.disqus.com/embed.js",i.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(i)})</script>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Back to top
          </a>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../pytorch_logistic_regression/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Logistic Regression" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Logistic Regression
            </div>
          </div>
        </a>
      
      
        
        <a href="../pytorch_convolutional_neuralnetwork/" class="md-footer__link md-footer__link--next" aria-label="Next: Convolutional Neural Networks (CNN)" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Convolutional Neural Networks (CNN)
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2023 Deep Learning Wizard by Ritchie Ng
          </div>
        
        
      </div>
      
  <div class="md-footer-social">
    
      
      
        
        
      
      <a href="https://www.youtube.com/channel/UCJz2MIjiCosOQCwhnsYxeEw" target="_blank" rel="noopener" title="www.youtube.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg>
      </a>
    
      
      
        
        
      
      <a href="https://twitter.com/deeplearningwiz" target="_blank" rel="noopener" title="twitter.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
      </a>
    
      
      
        
        
      
      <a href="https://www.facebook.com/DeepLearningWizard/" target="_blank" rel="noopener" title="www.facebook.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg>
      </a>
    
      
      
        
        
      
      <a href="https://www.linkedin.com/company/deeplearningwizard/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
      </a>
    
      
      
        
        
      
      <a href="https://github.com/ritchieng" target="_blank" rel="noopener" title="github.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
      </a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.annotate", "content.tabs.link", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../../assets/javascripts/workers/search.709b4209.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.56838a2c.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>